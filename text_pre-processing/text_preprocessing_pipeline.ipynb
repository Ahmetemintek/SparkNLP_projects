{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_preprocessing_pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roUjobpptHMX"
      },
      "source": [
        "### Text Preprocessing Pipeline\n",
        "Basic data exploration operations with PySpark and creation of pipeline which involves preprocessing steps for NLP applications by using SparkNLP. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsqtdNUSFphQ"
      },
      "source": [
        "Setting up sparknlp and importing necessary libraries. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-kfy5BNqBAd",
        "outputId": "c6e145fd-d8b2-4e32-dd5f-1e5cb316e4a5"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/colab_setup.sh -O - | bash"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-16 20:44:46--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1608 (1.6K) [text/plain]\n",
            "Saving to: ‚ÄòSTDOUT‚Äô\n",
            "\n",
            "\r-                     0%[                    ]       0  --.-KB/s               setup Colab for PySpark 3.0.2 and Spark NLP 3.1.0\n",
            "\r-                   100%[===================>]   1.57K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2021-10-16 20:44:46 (1.72 MB/s) - written to stdout [1608/1608]\n",
            "\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,431 kB]\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [607 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,367 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,803 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,210 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [640 kB]\n",
            "Fetched 10.3 MB in 3s (3,424 kB/s)\n",
            "Reading package lists... Done\n",
            "tar: spark-3.0.2-bin-hadoop2.7.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 204.8 MB 55 kB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44 kB 1.5 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198 kB 51.4 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxLrFUAjtQlq"
      },
      "source": [
        "import sparknlp \n",
        "spark= sparknlp.start()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq33jps7tQjN"
      },
      "source": [
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.functions import count, when, isnan, col"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZU85k1Q1GO1X"
      },
      "source": [
        "Reading data and a little exploration through PySpark functions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOTKFuM7tQg2"
      },
      "source": [
        "df= spark.read\\\n",
        "    .option(\"header\", True)\\\n",
        "    .csv(\"/content/vaccination_tweets.csv\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXXUmssfG1qR",
        "outputId": "c789042d-ca23-45cc-cc6f-6955105e9df3"
      },
      "source": [
        "#displaying first 5 rows\n",
        "df.show(5, truncate=30)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+-------------------------+------------------------------+-------------------+--------------+------------+---------------+-------------+-------------------+------------------------------+------------------------------+-------------------+--------+---------+----------+\n",
            "|                 id|           user_name|            user_location|              user_description|       user_created|user_followers|user_friends|user_favourites|user_verified|               date|                          text|                      hashtags|             source|retweets|favorites|is_retweet|\n",
            "+-------------------+--------------------+-------------------------+------------------------------+-------------------+--------------+------------+---------------+-------------+-------------------+------------------------------+------------------------------+-------------------+--------+---------+----------+\n",
            "|1340539111971516416|          Rachel Roh|La Crescenta-Montrose, CA|Aggregator of Asian America...|2009-04-08 17:52:46|           405|        1692|           3247|        False|2020-12-20 06:06:44|Same folks said daikon past...|            ['PfizerBioNTech']|Twitter for Android|       0|        0|     False|\n",
            "|1338158543359250433|         Albert Fong|        San Francisco, CA|Marketing dude, tech geek, ...|2009-09-21 15:27:30|           834|         666|            178|        False|2020-12-13 16:27:13|While the world has been on...|                          null|    Twitter Web App|       1|        1|     False|\n",
            "|1337858199140118533|       eliüá±üáπüá™üá∫üëå|                 Your Bed|               heil, hydra üñê‚ò∫|2020-06-25 23:30:28|            10|          88|            155|        False|2020-12-12 20:33:45|#coronavirus #SputnikV #Ast...|['coronavirus', 'SputnikV',...|Twitter for Android|       0|        0|     False|\n",
            "|1337855739918835717|       Charles Adler|   Vancouver, BC - Canada|\"Hosting \"\"CharlesAdlerToni...|2008-09-10 11:28:53|         49165|        3933|          21853|         True|2020-12-12 20:23:59|Facts are immutable, Senato...|                          null|    Twitter Web App|     446|     2129|     False|\n",
            "|1337854064604966912|Citizen News Channel|                     null|Citizen News Channel bringi...|2020-04-23 17:58:42|           152|         580|           1473|        False|2020-12-12 20:17:19|Explain to me again why we ...|['whereareallthesickpeople'...| Twitter for iPhone|       0|        0|     False|\n",
            "+-------------------+--------------------+-------------------------+------------------------------+-------------------+--------------+------------+---------------+-------------+-------------------+------------------------------+------------------------------+-------------------+--------+---------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nir9S34_GHra",
        "outputId": "21b3b867-aeec-439f-ba46-63f725f6c38d"
      },
      "source": [
        "#checking column names\n",
        "df.columns"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['id',\n",
              " 'user_name',\n",
              " 'user_location',\n",
              " 'user_description',\n",
              " 'user_created',\n",
              " 'user_followers',\n",
              " 'user_friends',\n",
              " 'user_favourites',\n",
              " 'user_verified',\n",
              " 'date',\n",
              " 'text',\n",
              " 'hashtags',\n",
              " 'source',\n",
              " 'retweets',\n",
              " 'favorites',\n",
              " 'is_retweet']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUHvPU-qGHo0",
        "outputId": "221854a8-8ce3-4eb7-920b-ed742dddaeea"
      },
      "source": [
        "#checking column's data types\n",
        "df.dtypes"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('id', 'string'),\n",
              " ('user_name', 'string'),\n",
              " ('user_location', 'string'),\n",
              " ('user_description', 'string'),\n",
              " ('user_created', 'string'),\n",
              " ('user_followers', 'string'),\n",
              " ('user_friends', 'string'),\n",
              " ('user_favourites', 'string'),\n",
              " ('user_verified', 'string'),\n",
              " ('date', 'string'),\n",
              " ('text', 'string'),\n",
              " ('hashtags', 'string'),\n",
              " ('source', 'string'),\n",
              " ('retweets', 'string'),\n",
              " ('favorites', 'string'),\n",
              " ('is_retweet', 'string')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZEvzJ8TGHmT",
        "outputId": "150f1973-19d2-48ff-ea5b-447e9f8d507a"
      },
      "source": [
        "#compute summary statistics (not essential for text data though)\n",
        "df.describe().show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+--------------------+------------------+--------------------+------------------+--------------------+-------------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+--------------------+------------------+-----------------+\n",
            "|summary|                  id|           user_name|     user_location|    user_description|      user_created|      user_followers|       user_friends|     user_favourites|       user_verified|              date|                text|            hashtags|              source|            retweets|         favorites|       is_retweet|\n",
            "+-------+--------------------+--------------------+------------------+--------------------+------------------+--------------------+-------------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+--------------------+------------------+-----------------+\n",
            "|  count|                4184|                3495|              3044|                3447|              3243|                3239|               2578|                2519|                2342|              2380|                2378|                1377|                1780|                1597|              1587|             1584|\n",
            "|   mean|1.340339941599683...|              624.25| 64217.60912052117|   463.8503054989817|  4133.32664756447|   61060.87295263391| 1168.1806569343066|  12960.202293577982|              3231.2|           15736.0|   16.67379679144385|   7.865979381443299|  129.07142857142858|    1.87125557680051|11.485117162761242|4.166666666666667|\n",
            "| stddev|4.643037276271194...|   258.1877546799357|206483.32948058838|   2065.529382004887| 15787.90427274379|   495192.1564230057|  2525.014047478436|   39070.79643147444|  3920.4286557013693|21107.948514718337|  123.44227464655485|   41.85296960288343|  476.90064507686003|  13.327172106018578| 77.16846746080454|7.342463122541533|\n",
            "|    min|                 ...|                    |                  |                    |   #RefugeeHealth‚†Ä|            Military|              Coach|               Train| Facilitate& Ente...|     HubZone WOSB\"|\"\"\" #Happy and #S...| 70%) effective\"\"...| but I'm not happ...| both sexes and i...|                 0|                0|\n",
            "|    max|ü¶† Ireland is now...|ü¶ëDr. Kraken-Elec...|               üåç |ü´ÅPCCM fellowü´Ä@B...|Twitter for iPhone|['coronavirus', '...|Twitter for Android|üá∫üá∏ has ledüåé to...|üíâ‚úÖ‚õîÔ∏èTo vax or no...|       ['vaccine']|ü¶† Full report on...|‚Ä¶ https://t.co/Ig...|['inoculated', 'P...| Twitter for Android|   Twitter Web App|  Twitter Web App|\n",
            "+-------+--------------------+--------------------+------------------+--------------------+------------------+--------------------+-------------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+--------------------+------------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvOqdx4sGxhQ",
        "outputId": "5d62c42f-5ccb-46f0-b28f-1a5339fd033e"
      },
      "source": [
        "#print the schema of df\n",
        "df.printSchema()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- user_name: string (nullable = true)\n",
            " |-- user_location: string (nullable = true)\n",
            " |-- user_description: string (nullable = true)\n",
            " |-- user_created: string (nullable = true)\n",
            " |-- user_followers: string (nullable = true)\n",
            " |-- user_friends: string (nullable = true)\n",
            " |-- user_favourites: string (nullable = true)\n",
            " |-- user_verified: string (nullable = true)\n",
            " |-- date: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- hashtags: string (nullable = true)\n",
            " |-- source: string (nullable = true)\n",
            " |-- retweets: string (nullable = true)\n",
            " |-- favorites: string (nullable = true)\n",
            " |-- is_retweet: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjVNy1dGGxeP",
        "outputId": "76a9b45f-5d67-4178-9104-bbc59080213c"
      },
      "source": [
        "#checking for null values for 'text' column\n",
        "df.select(count(when(isnan(\"text\") | col(\"text\").isNull(), \"text\")).alias(\"text\")).show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+\n",
            "|text|\n",
            "+----+\n",
            "|1806|\n",
            "+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAOY0wJOJ3-L"
      },
      "source": [
        "There are null values in text, we will drop these."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBQ2pFqSGxbR",
        "outputId": "f5010a72-f56b-4708-a021-d46dd2a34564"
      },
      "source": [
        "df= df.na.drop()\n",
        "df.select(count(when(isnan(\"text\") | col(\"text\").isNull(), \"text\")).alias(\"text\")).show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+\n",
            "|text|\n",
            "+----+\n",
            "|   0|\n",
            "+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4dL23-RJ-x-"
      },
      "source": [
        "Great! Starting generate the text pre-processing steps with SparkNLP annotators and models. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggsmfzxrO_hn"
      },
      "source": [
        "#as we will use only text column\n",
        "df= df.select(\"text\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEQVlTjBLOyA"
      },
      "source": [
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVf9nQL1Jznc",
        "outputId": "3c88e9cf-f5a3-4e59-c77f-ee2639929603"
      },
      "source": [
        "documentAssembler= DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer= Tokenizer()\\\n",
        "    .setInputCols([\"document\"])\\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "normalizer= Normalizer()\\\n",
        "    .setInputCols([\"token\"])\\\n",
        "    .setOutputCol( \"normalized\")\\\n",
        "    .setLowercase(True)\n",
        "\n",
        "stopwords_cleaner= StopWordsCleaner()\\\n",
        "    .setInputCols(\"normalized\")\\\n",
        "    .setOutputCol(\"cleaned\")\\\n",
        "    .setCaseSensitive(False)\n",
        "\n",
        "lemmatizer_model = LemmatizerModel.pretrained('lemma_antbnc', 'en') \\\n",
        "    .setInputCols([\"cleaned\"]) \\\n",
        "    .setOutputCol(\"lemma\")\n",
        "\n",
        "bert_embedding= BertEmbeddings.pretrained(\"bert_base_cased\", \"en\")\\\n",
        "    .setInputCols([\"document\", \"lemma\"])\\\n",
        "    .setOutputCol(\"bert_embedding\")\\\n",
        "    .setCaseSensitive(True)\n",
        "\n",
        "sentence_embedding= SentenceEmbeddings()\\\n",
        "    .setInputCols([\"document\", \"bert_embedding\"])\\\n",
        "    .setOutputCol(\"sentence_embedding\")\\\n",
        "    .setPoolingStrategy(\"AVERAGE\")\n",
        "\n",
        "embedding_finisher= EmbeddingsFinisher()\\\n",
        "    .setInputCols([\"sentence_embedding\"])\\\n",
        "    .setOutputCols([\"finished_sentence_embedding\"])\\\n",
        "    .setOutputAsVector(True)\\\n",
        "    .setCleanAnnotations(False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lemma_antbnc download started this may take some time.\n",
            "Approximate size to download 907.6 KB\n",
            "[OK!]\n",
            "bert_base_cased download started this may take some time.\n",
            "Approximate size to download 389.1 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WkLU0dJLXkk"
      },
      "source": [
        "Now, putting all these pre-processing steps into the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0H4uyY_LRoy"
      },
      "source": [
        "#importing PySpark's Pipeline\n",
        "from pyspark.ml import Pipeline"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua8j2V-hJzkC"
      },
      "source": [
        "nlp_pipeline= Pipeline(stages= [\n",
        "                                documentAssembler,\n",
        "                                tokenizer,\n",
        "                                normalizer,\n",
        "                                stopwords_cleaner,\n",
        "                                lemmatizer_model,\n",
        "                                bert_embedding,\n",
        "                                sentence_embedding,\n",
        "                                embedding_finisher\n",
        "])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y97WRSCDMKfb"
      },
      "source": [
        "Now we have pipeline called 'nlp_pipeline' as ready to fit and transform processes. <br/>\n",
        "We fit our pipeline first with empty dataFrame in order to enable it to transform with any dataFrame. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vG_dtGGQMFqK",
        "outputId": "ef5fbd74-eb45-4230-f9b3-b9dfc12a65c7"
      },
      "source": [
        "%%time\n",
        "empty_df= spark.createDataFrame([[\" \"]]).toDF(\"text\")   #empty_df has been created with 1 'text' column\n",
        "nlp_model= nlp_pipeline.fit(df)  "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 67 ms, sys: 11 ms, total: 78 ms\n",
            "Wall time: 872 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lam3clabMmjo"
      },
      "source": [
        "#transforming nlp_model with our dataset\n",
        "result= nlp_model.transform(df)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v197V1cyObXi"
      },
      "source": [
        "Inspecting the results of pre-processing transactions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDrxYOYtMpgc",
        "outputId": "7cde77a3-3ef1-463c-a31a-b4fb7c7c6151"
      },
      "source": [
        "result.show(5, truncate=30)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+\n",
            "|                          text|                      document|                         token|                    normalized|                       cleaned|                         lemma|                bert_embedding|            sentence_embedding|   finished_sentence_embedding|\n",
            "+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+\n",
            "|Same folks said daikon past...|[[document, 0, 96, Same fol...|[[token, 0, 3, Same, [sente...|[[token, 0, 3, same, [sente...|[[token, 5, 9, folks, [sent...|[[token, 5, 9, folk, [sente...|[[word_embeddings, 5, 9, fo...|[[sentence_embeddings, 0, 9...|[[0.32428109645843506,-0.16...|\n",
            "|#coronavirus #SputnikV #Ast...|[[document, 0, 139, #corona...|[[token, 0, 11, #coronaviru...|[[token, 0, 10, coronavirus...|[[token, 0, 10, coronavirus...|[[token, 0, 10, coronavirus...|[[word_embeddings, 0, 10, c...|[[sentence_embeddings, 0, 1...|[[0.4382466971874237,-0.217...|\n",
            "|it is a bit sad to claim th...|[[document, 0, 138, it is a...|[[token, 0, 1, it, [sentenc...|[[token, 0, 1, it, [sentenc...|[[token, 8, 10, bit, [sente...|[[token, 8, 10, bit, [sente...|[[word_embeddings, 8, 10, b...|[[sentence_embeddings, 0, 1...|[[0.0014825636753812432,-0....|\n",
            "|Coronavirus: Iran reports 8...|[[document, 0, 133, Coronav...|[[token, 0, 10, Coronavirus...|[[token, 0, 10, coronavirus...|[[token, 0, 10, coronavirus...|[[token, 0, 10, coronavirus...|[[word_embeddings, 0, 10, c...|[[sentence_embeddings, 0, 1...|[[0.4469470679759979,-0.290...|\n",
            "|The trump administration fa...|[[document, 0, 135, The tru...|[[token, 0, 2, The, [senten...|[[token, 0, 2, the, [senten...|[[token, 4, 8, trump, [sent...|[[token, 4, 8, trump, [sent...|[[word_embeddings, 4, 8, tr...|[[sentence_embeddings, 0, 1...|[[0.5595207810401917,-0.094...|\n",
            "+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dezS0u36MpcQ",
        "outputId": "a06fa493-30b1-4236-f251-3799c9e339f5"
      },
      "source": [
        "result.printSchema()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- text: string (nullable = true)\n",
            " |-- document: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- normalized: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- cleaned: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- lemma: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- bert_embedding: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = false)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- sentence_embedding: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- finished_sentence_embedding: array (nullable = true)\n",
            " |    |-- element: vector (containsNull = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziGUz2Ic6DLJ"
      },
      "source": [
        "Word embedding results. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_GX_x_3PJgJ",
        "outputId": "0833ee54-bc70-4e31-a600-a792e2e529a2"
      },
      "source": [
        "result.select(F.explode(F.arrays_zip(\"lemma.result\", \"bert_embedding.embeddings\")).alias(\"col\"))\\\n",
        "      .select(F.expr(\"col['0']\").alias(\"lemma\"),\n",
        "            F.expr(\"col['1']\").alias(\"bert\")).show(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+--------------------+\n",
            "|            lemma|                bert|\n",
            "+-----------------+--------------------+\n",
            "|             folk|[-0.058960535, -0...|\n",
            "|              say|[-0.4545134, -0.3...|\n",
            "|           daikon|[0.3539787, 0.225...|\n",
            "|            paste|[0.33013698, 0.00...|\n",
            "|            treat|[0.1006234, -0.52...|\n",
            "|         cytokine|[1.1752083, 0.427...|\n",
            "|            storm|[0.23642492, -0.3...|\n",
            "|   pfizerbiontech|[0.47123566, -0.9...|\n",
            "|httpstcoxehhimgkf|[0.7643941, 0.228...|\n",
            "|      coronavirus|[0.8943809, -0.28...|\n",
            "+-----------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OLTvVrJ5-jG"
      },
      "source": [
        "Here are sentence embedding results.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHhHLMsV5dXx",
        "outputId": "62aea5ac-c484-4e01-8a4f-9c301f3e7bb4"
      },
      "source": [
        "result.select(\"text\", \"sentence_embedding.embeddings\", \"finished_sentence_embedding\").show(5, truncate=50)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
            "|                                              text|                                        embeddings|                       finished_sentence_embedding|\n",
            "+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
            "|Same folks said daikon paste could treat a cyto...|[[0.3242811, -0.16343313, 0.09832452, 0.4089455...|[[0.32428109645843506,-0.16343313455581665,0.09...|\n",
            "|#coronavirus #SputnikV #AstraZeneca #PfizerBioN...|[[0.4382467, -0.21708411, 0.13505672, 0.2224946...|[[0.4382466971874237,-0.2170841097831726,0.1350...|\n",
            "|it is a bit sad to claim the fame for success o...|[[0.0014825637, -0.039872296, -0.06721318, 0.17...|[[0.0014825636753812432,-0.039872296154499054,-...|\n",
            "|Coronavirus: Iran reports 8,201 new cases, 221 ...|[[0.44694707, -0.2905127, 0.052604973, 0.147091...|[[0.4469470679759979,-0.29051271080970764,0.052...|\n",
            "|The trump administration failed to deliver on v...|[[0.5595208, -0.09457927, 0.19710808, 0.0445824...|[[0.5595207810401917,-0.09457927197217941,0.197...|\n",
            "+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAJAVBaZR2zU"
      },
      "source": [
        "Inspecting by Pandas dataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBJwmD51722t"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DihCHyW089nD",
        "outputId": "af7ffe4c-fca2-48d5-9040-d27bb97a3784"
      },
      "source": [
        "result.select(\"token.result\").show(5)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|              result|\n",
            "+--------------------+\n",
            "|[Same, folks, sai...|\n",
            "|[#coronavirus, #S...|\n",
            "|[it, is, a, bit, ...|\n",
            "|[Coronavirus, :, ...|\n",
            "|[The, trump, admi...|\n",
            "+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-lLbRyzQfeu"
      },
      "source": [
        "df= result.select(F.explode(F.arrays_zip(\"cleaned.result\", \"lemma.result\", \"bert_embedding.embeddings\")).alias(\"col\"))\\\n",
        "    .select(F.expr(\"col['0']\").alias(\"cleaned\"),\n",
        "            F.expr(\"col['1']\").alias(\"lemma\"),\n",
        "            F.expr(\"col['2']\").alias(\"bert_embedding\")).toPandas()"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H55VIuD6QfZs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "f3f4ae6a-aa5c-4804-b42f-452fd4a059fd"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned</th>\n",
              "      <th>lemma</th>\n",
              "      <th>bert_embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>folks</td>\n",
              "      <td>folk</td>\n",
              "      <td>[-0.05896046757698059, -0.2533942461013794, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>said</td>\n",
              "      <td>say</td>\n",
              "      <td>[-0.454512357711792, -0.3617393374443054, 0.08...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>daikon</td>\n",
              "      <td>daikon</td>\n",
              "      <td>[0.3539792597293854, 0.22553156316280365, 0.10...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>paste</td>\n",
              "      <td>paste</td>\n",
              "      <td>[0.3301369845867157, 0.0037823885213583708, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>treat</td>\n",
              "      <td>treat</td>\n",
              "      <td>[0.10062337666749954, -0.5281332731246948, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>cytokine</td>\n",
              "      <td>cytokine</td>\n",
              "      <td>[1.1752082109451294, 0.4270249307155609, -0.16...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>storm</td>\n",
              "      <td>storm</td>\n",
              "      <td>[0.23642480373382568, -0.3116196393966675, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>pfizerbiontech</td>\n",
              "      <td>pfizerbiontech</td>\n",
              "      <td>[0.4712355434894562, -0.9010103344917297, 0.32...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>httpstcoxehhimgkf</td>\n",
              "      <td>httpstcoxehhimgkf</td>\n",
              "      <td>[0.7643942832946777, 0.22865983843803406, 0.58...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>coronavirus</td>\n",
              "      <td>coronavirus</td>\n",
              "      <td>[0.8943809270858765, -0.28010478615760803, -0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             cleaned  ...                                     bert_embedding\n",
              "0              folks  ...  [-0.05896046757698059, -0.2533942461013794, 0....\n",
              "1               said  ...  [-0.454512357711792, -0.3617393374443054, 0.08...\n",
              "2             daikon  ...  [0.3539792597293854, 0.22553156316280365, 0.10...\n",
              "3              paste  ...  [0.3301369845867157, 0.0037823885213583708, 0....\n",
              "4              treat  ...  [0.10062337666749954, -0.5281332731246948, -0....\n",
              "5           cytokine  ...  [1.1752082109451294, 0.4270249307155609, -0.16...\n",
              "6              storm  ...  [0.23642480373382568, -0.3116196393966675, -0....\n",
              "7     pfizerbiontech  ...  [0.4712355434894562, -0.9010103344917297, 0.32...\n",
              "8  httpstcoxehhimgkf  ...  [0.7643942832946777, 0.22865983843803406, 0.58...\n",
              "9        coronavirus  ...  [0.8943809270858765, -0.28010478615760803, -0....\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFlu1fyk-lg6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
