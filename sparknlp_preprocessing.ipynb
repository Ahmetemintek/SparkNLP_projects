{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sparknlp_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5n-PbWgvZcWT"
      },
      "source": [
        "## Text Preprocessing with SparkNLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tbdyXHxCIIO"
      },
      "source": [
        "#data\n",
        "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jupyter/annotation/english/spark-nlp-basics/sample-sentences-en.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5kvnzu3l2zE",
        "outputId": "47058084-a046-42bd-fe9b-a4e3af745779"
      },
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-27 19:54:55--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://setup.johnsnowlabs.com/colab.sh [following]\n",
            "--2021-09-27 19:54:55--  https://setup.johnsnowlabs.com/colab.sh\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2021-09-27 19:54:55--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1608 (1.6K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "setup Colab for PySpark 3.0.3 and Spark NLP 3.2.3\n",
            "-                   100%[===================>]   1.57K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-09-27 19:54:56 (42.6 MB/s) - written to stdout [1608/1608]\n",
            "\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:10 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [67.9 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,335 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,428 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [581 kB]\n",
            "Hit:17 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:18 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,202 kB]\n",
            "Get:20 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,802 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [627 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,787 kB]\n",
            "Get:24 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [922 kB]\n",
            "Get:25 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [42.0 kB]\n",
            "Fetched 13.1 MB in 9s (1,461 kB/s)\n",
            "Reading package lists... Done\n",
            "\u001b[K     |████████████████████████████████| 209.1 MB 55 kB/s \n",
            "\u001b[K     |████████████████████████████████| 118 kB 46.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 53.7 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca1UC1VpdUj9"
      },
      "source": [
        "import sparknlp\n",
        "spark= sparknlp.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0PcWptrhByl",
        "outputId": "e0772622-ace4-4636-f659-31409dfa0847"
      },
      "source": [
        "text= \"Galatasaray is the firts club that has won the UEFA cup in Turkey\"\n",
        "\n",
        "spark_df= spark.createDataFrame([[text]]).toDF(\"text\")\n",
        "spark_df.show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------------+\n",
            "|text                                                             |\n",
            "+-----------------------------------------------------------------+\n",
            "|Galatasaray is the firts club that has won the UEFA cup in Turkey|\n",
            "+-----------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rn8mmAaehr8R"
      },
      "source": [
        "# to create sparkDF from a list of string\n",
        "from pyspark.sql.types import StringType, IntegerType"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTQH55Rzh8sU",
        "outputId": "3f909b85-8557-4e1f-9a5b-a53b1f84f031"
      },
      "source": [
        "text_list = ['Peter Parker is a nice guy and lives in New York.', 'Bruce Wayne is also a nice guy and lives in Gotham City.']\n",
        "spark.createDataFrame(text_list, StringType()).toDF(\"text\").show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------+\n",
            "|text                                                    |\n",
            "+--------------------------------------------------------+\n",
            "|Peter Parker is a nice guy and lives in New York.       |\n",
            "|Bruce Wayne is also a nice guy and lives in Gotham City.|\n",
            "+--------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx9N-CiJh8pL"
      },
      "source": [
        "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jupyter/annotation/english/spark-nlp-basics/sample-sentences-en.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kauTv80ah8lc",
        "outputId": "94ef2655-02d8-41c7-dcd6-2634b79ca06b"
      },
      "source": [
        "with open(\"/content/sample-sentences-en.txt\") as f:\n",
        "  print(f.read())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Peter is a very good person.\n",
            "My life in Russia is very interesting.\n",
            "John and Peter are brothers. However they don't support each other that much.\n",
            "Lucas Nogal Dunbercker is no longer happy. He has a good car though.\n",
            "Europe is very culture rich. There are huge churches! and big houses!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMcBgr8XjDGb",
        "outputId": "08c191fb-924d-4ce2-97d3-b3e3e9ef93f1"
      },
      "source": [
        "df= spark.read.text(\"/content/sample-sentences-en.txt\").toDF(\"text\")\n",
        "df.show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------------------------+\n",
            "|text                                                                         |\n",
            "+-----------------------------------------------------------------------------+\n",
            "|Peter is a very good person.                                                 |\n",
            "|My life in Russia is very interesting.                                       |\n",
            "|John and Peter are brothers. However they don't support each other that much.|\n",
            "|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |\n",
            "|Europe is very culture rich. There are huge churches! and big houses!        |\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmXIw3ZojNb8",
        "outputId": "1db49a14-fde2-4936-a3eb-87553e99ef61"
      },
      "source": [
        "text_files= spark.sparkContext.wholeTextFiles(\"./*.txt\", 2)\n",
        "text_folder_df= text_files.toDF(schema=[\"path\", \"text\"])\n",
        "text_folder_df.show(truncate=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+\n",
            "|                path|                text|\n",
            "+--------------------+--------------------+\n",
            "|file:/content/sam...|Peter is a very g...|\n",
            "+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrxHeK8ijNYu",
        "outputId": "d33c885c-5b78-44ff-be53-9e88c5de1a1f"
      },
      "source": [
        "text_folder_df.select(\"text\").take(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(text=\"Peter is a very good person.\\nMy life in Russia is very interesting.\\nJohn and Peter are brothers. However they don't support each other that much.\\nLucas Nogal Dunbercker is no longer happy. He has a good car though.\\nEurope is very culture rich. There are huge churches! and big houses!\")]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQocJ3HwjNV5",
        "outputId": "cea974a0-a7a6-4cb4-f34d-8e2ae10cb9e3"
      },
      "source": [
        "text_folder_df.select(\"text\").collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(text=\"Peter is a very good person.\\nMy life in Russia is very interesting.\\nJohn and Peter are brothers. However they don't support each other that much.\\nLucas Nogal Dunbercker is no longer happy. He has a good car though.\\nEurope is very culture rich. There are huge churches! and big houses!\")]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6McwdWdTklmM",
        "outputId": "fc077dc7-76f5-4bb8-fc20-c5a41eb7ac8b"
      },
      "source": [
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|                text|\n",
            "+--------------------+\n",
            "|Peter is a very g...|\n",
            "|My life in Russia...|\n",
            "|John and Peter ar...|\n",
            "|Lucas Nogal Dunbe...|\n",
            "|Europe is very cu...|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTjeE5ablb24"
      },
      "source": [
        "from sparknlp.base import * "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5CVSA3Ylk-6"
      },
      "source": [
        "documentAssembler= DocumentAssembler()\\\n",
        "      .setInputCol(\"text\")\\\n",
        "      .setOutputCol(\"document\")\\\n",
        "      .setCleanupMode(\"shrink\")\n",
        "\n",
        "doc_df= documentAssembler.transform(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rgOoNRxlk7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4711a2ba-c19b-4eb5-ab21-ae04f3525c63"
      },
      "source": [
        "doc_df.show(truncate=60)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------------------+------------------------------------------------------------+\n",
            "|                                                        text|                                                    document|\n",
            "+------------------------------------------------------------+------------------------------------------------------------+\n",
            "|                                Peter is a very good person.|[[document, 0, 27, Peter is a very good person., [sentenc...|\n",
            "|                      My life in Russia is very interesting.|[[document, 0, 37, My life in Russia is very interesting....|\n",
            "|John and Peter are brothers. However they don't support e...|[[document, 0, 76, John and Peter are brothers. However t...|\n",
            "|Lucas Nogal Dunbercker is no longer happy. He has a good ...|[[document, 0, 67, Lucas Nogal Dunbercker is no longer ha...|\n",
            "|Europe is very culture rich. There are huge churches! and...|[[document, 0, 68, Europe is very culture rich. There are...|\n",
            "+------------------------------------------------------------+------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TK3LKoH-lk3n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "313f4d0a-4b5d-47e0-c22f-853a186ef4bc"
      },
      "source": [
        "doc_df.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- text: string (nullable = true)\n",
            " |-- document: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iRlFm5fpbcK",
        "outputId": "9fc33e5e-49e3-4db9-c1c6-a9316a10152f"
      },
      "source": [
        "doc_df.select(\"document.result\", \"document.begin\", \"document.end\").show(truncate=40)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------+-----+----+\n",
            "|                                  result|begin| end|\n",
            "+----------------------------------------+-----+----+\n",
            "|          [Peter is a very good person.]|  [0]|[27]|\n",
            "|[My life in Russia is very interesting.]|  [0]|[37]|\n",
            "|[John and Peter are brothers. However...|  [0]|[76]|\n",
            "|[Lucas Nogal Dunbercker is no longer ...|  [0]|[67]|\n",
            "|[Europe is very culture rich. There a...|  [0]|[68]|\n",
            "+----------------------------------------+-----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLaGq0iZpcef",
        "outputId": "16aa24d1-d910-45db-d22d-ed9ce5d127a1"
      },
      "source": [
        "doc_df.select(\"document.result\").take(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(result=['Peter is a very good person.'])]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlsGFx9jpcXM"
      },
      "source": [
        "from sparknlp.annotator import * "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCx4bZWmqJUJ"
      },
      "source": [
        "sentence= SentenceDetector()\\\n",
        "      .setInputCols([\"document\"])\\\n",
        "      .setOutputCol(\"sentence\")\n",
        "    \n",
        "sent_df= sentence.transform(doc_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CE3ujAWsqJQN",
        "outputId": "1f9813d3-7150-4f84-d4bf-031804e38629"
      },
      "source": [
        "sent_df.show(truncate=40)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------+----------------------------------------+----------------------------------------+\n",
            "|                                    text|                                document|                                sentence|\n",
            "+----------------------------------------+----------------------------------------+----------------------------------------+\n",
            "|            Peter is a very good person.|[[document, 0, 27, Peter is a very go...|[[document, 0, 27, Peter is a very go...|\n",
            "|  My life in Russia is very interesting.|[[document, 0, 37, My life in Russia ...|[[document, 0, 37, My life in Russia ...|\n",
            "|John and Peter are brothers. However ...|[[document, 0, 76, John and Peter are...|[[document, 0, 27, John and Peter are...|\n",
            "|Lucas Nogal Dunbercker is no longer h...|[[document, 0, 67, Lucas Nogal Dunber...|[[document, 0, 41, Lucas Nogal Dunber...|\n",
            "|Europe is very culture rich. There ar...|[[document, 0, 68, Europe is very cul...|[[document, 0, 27, Europe is very cul...|\n",
            "+----------------------------------------+----------------------------------------+----------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d3p_7fOqJMt",
        "outputId": "2e2c0b80-db11-426b-bd56-1480d4f483aa"
      },
      "source": [
        "sentence.extractParamMap()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{Param(parent='SentenceDetector_fb7d225876cf', name='customBounds', doc='characters used to explicitly mark sentence bounds'): [],\n",
              " Param(parent='SentenceDetector_fb7d225876cf', name='detectLists', doc='whether detect lists during sentence detection'): True,\n",
              " Param(parent='SentenceDetector_fb7d225876cf', name='explodeSentences', doc='whether to explode each sentence into a different row, for better parallelization. Defaults to false.'): False,\n",
              " Param(parent='SentenceDetector_fb7d225876cf', name='inputCols', doc='previous annotations columns, if renamed'): ['document'],\n",
              " Param(parent='SentenceDetector_fb7d225876cf', name='lazyAnnotator', doc='Whether this AnnotatorModel acts as lazy in RecursivePipelines'): False,\n",
              " Param(parent='SentenceDetector_fb7d225876cf', name='maxLength', doc='Set the maximum allowed length for each sentence'): 99999,\n",
              " Param(parent='SentenceDetector_fb7d225876cf', name='minLength', doc='Set the minimum allowed length for each sentence.'): 0,\n",
              " Param(parent='SentenceDetector_fb7d225876cf', name='outputCol', doc='output annotation column. can be left default.'): 'sentence',\n",
              " Param(parent='SentenceDetector_fb7d225876cf', name='useAbbreviations', doc='whether to apply abbreviations at sentence detection'): True,\n",
              " Param(parent='SentenceDetector_fb7d225876cf', name='useCustomBoundsOnly', doc='Only utilize custom bounds in sentence detection'): False}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EI5uCFRXrx03",
        "outputId": "8db58f16-c891-49e4-aae6-0fa2e4c870b6"
      },
      "source": [
        "sent_df.select(\"sentence.result\").show(truncate=40)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------+\n",
            "|                                  result|\n",
            "+----------------------------------------+\n",
            "|          [Peter is a very good person.]|\n",
            "|[My life in Russia is very interesting.]|\n",
            "|[John and Peter are brothers., Howeve...|\n",
            "|[Lucas Nogal Dunbercker is no longer ...|\n",
            "|[Europe is very culture rich., There ...|\n",
            "+----------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBXmCFpns8a6",
        "outputId": "52422d35-6ed0-4c4f-8a12-a5113b5a389e"
      },
      "source": [
        "sent_dl= SentenceDetectorDLModel()\\\n",
        "      .pretrained(\"sentence_detector_dl\", \"en\")\\\n",
        "      .setInputCols([\"document\"])\\\n",
        "      .setOutputCol(\"sentences\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence_detector_dl download started this may take some time.\n",
            "Approximate size to download 354.6 KB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgHEbWD1t13K",
        "outputId": "8fd47c28-8c3d-4525-f725-8465fb06c335"
      },
      "source": [
        "sent_dl_df= sent_dl.transform(doc_df)\n",
        "sent_dl_df.select(\"sentences.result\").show(truncate=40)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------+\n",
            "|                                  result|\n",
            "+----------------------------------------+\n",
            "|          [Peter is a very good person.]|\n",
            "|[My life in Russia is very interesting.]|\n",
            "|[John and Peter are brothers., Howeve...|\n",
            "|[Lucas Nogal Dunbercker is no longer ...|\n",
            "|[Europe is very culture rich., There ...|\n",
            "+----------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z04SJ4yWuLBX"
      },
      "source": [
        "from pyspark.sql import functions as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MYTrTI7uaZP",
        "outputId": "ac1e0bf5-26a6-4dc2-a332-e0f92f6916cd"
      },
      "source": [
        "sent_dl_df.select(F.explode(\"sentences.result\")).show(truncate=40)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------+\n",
            "|                                     col|\n",
            "+----------------------------------------+\n",
            "|            Peter is a very good person.|\n",
            "|  My life in Russia is very interesting.|\n",
            "|            John and Peter are brothers.|\n",
            "|However they don't support each other...|\n",
            "|Lucas Nogal Dunbercker is no longer h...|\n",
            "|               He has a good car though.|\n",
            "|            Europe is very culture rich.|\n",
            "|There are huge churches! and big houses!|\n",
            "+----------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q9K_2b0ukwG"
      },
      "source": [
        "tokenizer= Tokenizer()\\\n",
        "      .setInputCols([\"document\"])\\\n",
        "      .setOutputCol(\"token\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bRhyQRwyrAl",
        "outputId": "139e2953-52df-4ce1-e635-b9eaaadfb9a3"
      },
      "source": [
        "tokenizer.extractParamMap()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{Param(parent='Tokenizer_f40954ec1d53', name='caseSensitiveExceptions', doc='Whether to care for case sensitiveness in exceptions'): True,\n",
              " Param(parent='Tokenizer_f40954ec1d53', name='contextChars', doc='character list used to separate from token boundaries'): ['.',\n",
              "  ',',\n",
              "  ';',\n",
              "  ':',\n",
              "  '!',\n",
              "  '?',\n",
              "  '*',\n",
              "  '-',\n",
              "  '(',\n",
              "  ')',\n",
              "  '\"',\n",
              "  \"'\"],\n",
              " Param(parent='Tokenizer_f40954ec1d53', name='inputCols', doc='previous annotations columns, if renamed'): ['document'],\n",
              " Param(parent='Tokenizer_f40954ec1d53', name='lazyAnnotator', doc='Whether this AnnotatorModel acts as lazy in RecursivePipelines'): False,\n",
              " Param(parent='Tokenizer_f40954ec1d53', name='maxLength', doc='Set the maximum allowed legth for each token'): 99999,\n",
              " Param(parent='Tokenizer_f40954ec1d53', name='minLength', doc='Set the minimum allowed legth for each token'): 0,\n",
              " Param(parent='Tokenizer_f40954ec1d53', name='outputCol', doc='output annotation column. can be left default.'): 'token',\n",
              " Param(parent='Tokenizer_f40954ec1d53', name='targetPattern', doc='pattern to grab from text as token candidates. Defaults \\\\S+'): '\\\\S+'}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLa47cC7yq7K"
      },
      "source": [
        "text = 'Peter Parker (Spiderman) is a nice guy and lives in New York but has no e-mail!'\n",
        "\n",
        "spark_df= spark.createDataFrame([[text]]).toDF(\"text\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqrDVZbiyq2N",
        "outputId": "ca4ae55c-a5d2-4501-abf0-8349ee4abaa1"
      },
      "source": [
        "doc_df= documentAssembler.transform(spark_df)\n",
        "token_df= tokenizer.fit(doc_df).transform(doc_df)\n",
        "token_df.show(truncate=40)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------+----------------------------------------+----------------------------------------+\n",
            "|                                    text|                                document|                                   token|\n",
            "+----------------------------------------+----------------------------------------+----------------------------------------+\n",
            "|Peter Parker (Spiderman) is a nice gu...|[[document, 0, 78, Peter Parker (Spid...|[[token, 0, 4, Peter, [sentence -> 0]...|\n",
            "+----------------------------------------+----------------------------------------+----------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QSQNiyMyqxH",
        "outputId": "59de4607-cae7-424a-eff9-f616d19013f3"
      },
      "source": [
        "token_df.select(\"token.result\").take(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(result=['Peter', 'Parker', '(', 'Spiderman', ')', 'is', 'a', 'nice', 'guy', 'and', 'lives', 'in', 'New', 'York', 'but', 'has', 'no', 'e-mail', '!'])]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wc34r--kz1pr",
        "outputId": "a8bd4604-9652-4615-84d1-f12a5c0d3ca6"
      },
      "source": [
        "tokenizer= Tokenizer()\\\n",
        "      .setInputCols([\"document\"])\\\n",
        "      .setOutputCol(\"token\")\\\n",
        "      .setContextChars([\"?\", \"!\"])\\\n",
        "      .setSplitChars([\"-\"])\\\n",
        "      .addException(\"New York\")\n",
        "\n",
        "token_df= tokenizer.fit(doc_df).transform(doc_df)\n",
        "token_df.show(truncate=40)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------+----------------------------------------+----------------------------------------+\n",
            "|                                    text|                                document|                                   token|\n",
            "+----------------------------------------+----------------------------------------+----------------------------------------+\n",
            "|Peter Parker (Spiderman) is a nice gu...|[[document, 0, 78, Peter Parker (Spid...|[[token, 0, 4, Peter, [sentence -> 0]...|\n",
            "+----------------------------------------+----------------------------------------+----------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hu7YuGhz1kC",
        "outputId": "299e605c-4b17-4e12-cfd1-0fee44388b23"
      },
      "source": [
        "token_df.select(\"token.result\").show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------------------------+\n",
            "|result                                                                                            |\n",
            "+--------------------------------------------------------------------------------------------------+\n",
            "|[Peter, Parker, (Spiderman), is, a, nice, guy, and, lives, in, New York, but, has, no, e, mail, !]|\n",
            "+--------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QE955YN13Ajw"
      },
      "source": [
        "## Spark ML Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fCNYlkV1jQu"
      },
      "source": [
        "from pyspark.ml import Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_FluQA819Q0"
      },
      "source": [
        "documentAssembler= DocumentAssembler()\\\n",
        "      .setInputCol(\"text\")\\\n",
        "      .setOutputCol(\"document\")\n",
        "\n",
        "sentencer= SentenceDetector()\\\n",
        "      .setInputCols([\"document\"])\\\n",
        "      .setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer= Tokenizer()\\\n",
        "      .setInputCols([\"sentence\"])\\\n",
        "      .setOutputCol(\"token\")\\\n",
        "      .setSplitChars([\"-\"])\\\n",
        "      .setContextChars([\"?\", \"!\"])\n",
        " \n",
        " \n",
        "nlp_pipeline= Pipeline(stages=[\n",
        "                               documentAssembler,\n",
        "                               sentencer,\n",
        "                               tokenizer\n",
        " ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87jKQVMU19Lb"
      },
      "source": [
        "df= spark.read.text(\"/content/sample-sentences-en.txt\").toDF(\"text\")\n",
        "empty_df= spark.createDataFrame([[\" \"]]).toDF(\"text\")\n",
        "\n",
        "pipeline_model= nlp_pipeline.fit(empty_df)\n",
        "result= pipeline_model.transform(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N0r1D2b19F9",
        "outputId": "5069c15c-ffb3-475f-8b06-380e1cfcb3be"
      },
      "source": [
        "result.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|Peter is a very g...|[[document, 0, 27...|[[document, 0, 27...|[[token, 0, 4, Pe...|\n",
            "|My life in Russia...|[[document, 0, 37...|[[document, 0, 37...|[[token, 0, 1, My...|\n",
            "|John and Peter ar...|[[document, 0, 76...|[[document, 0, 27...|[[token, 0, 3, Jo...|\n",
            "|Lucas Nogal Dunbe...|[[document, 0, 67...|[[document, 0, 41...|[[token, 0, 4, Lu...|\n",
            "|Europe is very cu...|[[document, 0, 68...|[[document, 0, 27...|[[token, 0, 5, Eu...|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6DbjVpq19Aq",
        "outputId": "92f8633a-0549-4898-dfcb-ebdced55b688"
      },
      "source": [
        "result.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- text: string (nullable = true)\n",
            " |-- document: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- sentence: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N77m7uZa44Mg",
        "outputId": "e2309440-182e-4b36-dc2c-c87f2056b1da"
      },
      "source": [
        "result.select(\"sentence.result\").show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------+\n",
            "|result                                                                          |\n",
            "+--------------------------------------------------------------------------------+\n",
            "|[Peter is a very good person.]                                                  |\n",
            "|[My life in Russia is very interesting.]                                        |\n",
            "|[John and Peter are brothers., However they don't support each other that much.]|\n",
            "|[Lucas Nogal Dunbercker is no longer happy., He has a good car though.]         |\n",
            "|[Europe is very culture rich., There are huge churches!, and big houses!]       |\n",
            "+--------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yLZas2P49LT"
      },
      "source": [
        "documentAssembler= DocumentAssembler()\\\n",
        "      .setInputCol(\"text\")\\\n",
        "      .setOutputCol(\"document\")\n",
        "\n",
        "sentencer= SentenceDetector()\\\n",
        "      .setInputCols([\"document\"])\\\n",
        "      .setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer= Tokenizer()\\\n",
        "      .setInputCols([\"sentence\"])\\\n",
        "      .setOutputCol(\"token\")\n",
        "\n",
        "normalizer= Normalizer()\\\n",
        "      .setInputCols([\"token\"])\\\n",
        "      .setOutputCol(\"normalized\")\\\n",
        "      .setLowercase(True)\\\n",
        "      .setCleanupPatterns([\"[^\\w\\d\\s]\"])   \n",
        "\n",
        "nlpPipeline= Pipeline(stages=[ \n",
        "                              documentAssembler,\n",
        "                              sentencer,\n",
        "                              tokenizer,\n",
        "                              normalizer\n",
        "])\n",
        "\n",
        "empty_df= spark.createDataFrame([[\" \"]]).toDF(\"text\")\n",
        "\n",
        "pipeline_model= nlpPipeline.fit(empty_df)\n",
        "\n",
        "result= pipeline_model.transform(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhJrHUna49FX",
        "outputId": "02181601-66fe-490c-d7e0-8ddba9bae1d5"
      },
      "source": [
        "result.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- text: string (nullable = true)\n",
            " |-- document: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- sentence: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- normalized: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liuKfaSM_Ene",
        "outputId": "6d1ae36b-e668-4104-d200-e79ed6f95d27"
      },
      "source": [
        "result.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|          normalized|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|Peter is a very g...|[[document, 0, 27...|[[document, 0, 27...|[[token, 0, 4, Pe...|[[token, 0, 4, pe...|\n",
            "|My life in Russia...|[[document, 0, 37...|[[document, 0, 37...|[[token, 0, 1, My...|[[token, 0, 1, my...|\n",
            "|John and Peter ar...|[[document, 0, 76...|[[document, 0, 27...|[[token, 0, 3, Jo...|[[token, 0, 3, jo...|\n",
            "|Lucas Nogal Dunbe...|[[document, 0, 67...|[[document, 0, 41...|[[token, 0, 4, Lu...|[[token, 0, 4, lu...|\n",
            "|Europe is very cu...|[[document, 0, 68...|[[document, 0, 27...|[[token, 0, 5, Eu...|[[token, 0, 5, eu...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzJRU9S1_LCH",
        "outputId": "34f29b9f-a65b-4128-8b91-83ffc53d5396"
      },
      "source": [
        "result.select(\"normalized.result\").take(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(result=['peter', 'is', 'a', 'very', 'good', 'person']),\n",
              " Row(result=['my', 'life', 'in', 'russia', 'is', 'very', 'interesting'])]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujOd57Z5_UeD",
        "outputId": "8dd5e42c-098d-4a23-e3ff-e59f746b6091"
      },
      "source": [
        "stopwords_cleaner= StopWordsCleaner()\\\n",
        "      .setInputCols([\"token\"])\\\n",
        "      .setOutputCol(\"cleaned\")\\\n",
        "      .setCaseSensitive(False)\\\n",
        "      #.setStopwords() ([\"no\", \"without\"]) (e.g. read a list of words from a txt)\n",
        "\n",
        "stopwords_cleaner.getStopWords()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " 'should',\n",
              " 'now',\n",
              " \"i'll\",\n",
              " \"you'll\",\n",
              " \"he'll\",\n",
              " \"she'll\",\n",
              " \"we'll\",\n",
              " \"they'll\",\n",
              " \"i'd\",\n",
              " \"you'd\",\n",
              " \"he'd\",\n",
              " \"she'd\",\n",
              " \"we'd\",\n",
              " \"they'd\",\n",
              " \"i'm\",\n",
              " \"you're\",\n",
              " \"he's\",\n",
              " \"she's\",\n",
              " \"it's\",\n",
              " \"we're\",\n",
              " \"they're\",\n",
              " \"i've\",\n",
              " \"we've\",\n",
              " \"you've\",\n",
              " \"they've\",\n",
              " \"isn't\",\n",
              " \"aren't\",\n",
              " \"wasn't\",\n",
              " \"weren't\",\n",
              " \"haven't\",\n",
              " \"hasn't\",\n",
              " \"hadn't\",\n",
              " \"don't\",\n",
              " \"doesn't\",\n",
              " \"didn't\",\n",
              " \"won't\",\n",
              " \"wouldn't\",\n",
              " \"shan't\",\n",
              " \"shouldn't\",\n",
              " \"mustn't\",\n",
              " \"can't\",\n",
              " \"couldn't\",\n",
              " 'cannot',\n",
              " 'could',\n",
              " \"here's\",\n",
              " \"how's\",\n",
              " \"let's\",\n",
              " 'ought',\n",
              " \"that's\",\n",
              " \"there's\",\n",
              " \"what's\",\n",
              " \"when's\",\n",
              " \"where's\",\n",
              " \"who's\",\n",
              " \"why's\",\n",
              " 'would']"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2AmAvq_BJd7"
      },
      "source": [
        "documentAssembler= DocumentAssembler()\\\n",
        "      .setInputCol(\"text\")\\\n",
        "      .setOutputCol(\"document\")\n",
        "\n",
        "sentencer= SentenceDetector()\\\n",
        "      .setInputCols([\"document\"])\\\n",
        "      .setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer= Tokenizer()\\\n",
        "      .setInputCols([\"sentence\"])\\\n",
        "      .setOutputCol(\"token\")\n",
        "\n",
        "nlpPipeline= Pipeline(stages= [ \n",
        "                               documentAssembler,\n",
        "                               sentencer,\n",
        "                               tokenizer,\n",
        "                               stopwords_cleaner\n",
        "])\n",
        "\n",
        "empty_df= spark.createDataFrame([[\" \"]]).toDF(\"text\")\n",
        "pipeline_model= nlpPipeline.fit(empty_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gE9tuMENBNPO",
        "outputId": "e49dfaf0-79d9-4666-da11-785d7bebeca7"
      },
      "source": [
        "result= pipeline_model.transform(df)\n",
        "result.show(truncate=40)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------+----------------------------------------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
            "|                                    text|                                document|                                sentence|                                   token|                                 cleaned|\n",
            "+----------------------------------------+----------------------------------------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
            "|            Peter is a very good person.|[[document, 0, 27, Peter is a very go...|[[document, 0, 27, Peter is a very go...|[[token, 0, 4, Peter, [sentence -> 0]...|[[token, 0, 4, Peter, [sentence -> 0]...|\n",
            "|  My life in Russia is very interesting.|[[document, 0, 37, My life in Russia ...|[[document, 0, 37, My life in Russia ...|[[token, 0, 1, My, [sentence -> 0], [...|[[token, 3, 6, life, [sentence -> 0],...|\n",
            "|John and Peter are brothers. However ...|[[document, 0, 76, John and Peter are...|[[document, 0, 27, John and Peter are...|[[token, 0, 3, John, [sentence -> 0],...|[[token, 0, 3, John, [sentence -> 0],...|\n",
            "|Lucas Nogal Dunbercker is no longer h...|[[document, 0, 67, Lucas Nogal Dunber...|[[document, 0, 41, Lucas Nogal Dunber...|[[token, 0, 4, Lucas, [sentence -> 0]...|[[token, 0, 4, Lucas, [sentence -> 0]...|\n",
            "|Europe is very culture rich. There ar...|[[document, 0, 68, Europe is very cul...|[[document, 0, 27, Europe is very cul...|[[token, 0, 5, Europe, [sentence -> 0...|[[token, 0, 5, Europe, [sentence -> 0...|\n",
            "+----------------------------------------+----------------------------------------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIICRCJBBNIP",
        "outputId": "0e9e677b-d119-45fe-aabe-cb26ef109144"
      },
      "source": [
        "result.select(\"cleaned.result\").show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------------------------+\n",
            "|result                                                            |\n",
            "+------------------------------------------------------------------+\n",
            "|[Peter, good, person, .]                                          |\n",
            "|[life, Russia, interesting, .]                                    |\n",
            "|[John, Peter, brothers, ., However, support, much, .]             |\n",
            "|[Lucas, Nogal, Dunbercker, longer, happy, ., good, car, though, .]|\n",
            "|[Europe, culture, rich, ., huge, churches, !, big, houses, !]     |\n",
            "+------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcUexrWMBNCB"
      },
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "sentencer = SentenceDetector()\\\n",
        "    .setInputCols(['document'])\\\n",
        "    .setOutputCol('sentences')\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"sentences\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "normalizer = Normalizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"normalized\")\\\n",
        "    .setLowercase(False)\\\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "    .setInputCols(\"normalized\")\\\n",
        "    .setOutputCol(\"cleanTokens\")\\\n",
        "    .setCaseSensitive(False)\\\n",
        "\n",
        "token_assembler= TokenAssembler()\\\n",
        "    .setInputCols([\"sentences\", \"cleanTokens\"])\\\n",
        "    .setOutputCol(\"assembled\")\n",
        "\n",
        "nlpPipeline= Pipeline(stages=[ \n",
        "                              documentAssembler,\n",
        "                              sentencer,\n",
        "                              tokenizer,\n",
        "                              normalizer,\n",
        "                              stopwords_cleaner,\n",
        "                              token_assembler\n",
        "])\n",
        "\n",
        "empty_df= spark.createDataFrame([[\" \"]]).toDF(\"text\")\n",
        "pipeline_model= nlpPipeline.fit(empty_df)\n",
        "\n",
        "result= pipeline_model.transform(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwwfCEi_DKvy",
        "outputId": "681d777a-6ae8-485a-e651-5448547244b4"
      },
      "source": [
        "result.show(truncate=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
            "|                                              text|                                          document|                                         sentences|                                             token|                                        normalized|                                       cleanTokens|                                         assembled|\n",
            "+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
            "|                      Peter is a very good person.|[[document, 0, 27, Peter is a very good person....|[[document, 0, 27, Peter is a very good person....|[[token, 0, 4, Peter, [sentence -> 0], []], [to...|[[token, 0, 4, Peter, [sentence -> 0], []], [to...|[[token, 0, 4, Peter, [sentence -> 0], []], [to...|[[document, 0, 16, Peter good person, [sentence...|\n",
            "|            My life in Russia is very interesting.|[[document, 0, 37, My life in Russia is very in...|[[document, 0, 37, My life in Russia is very in...|[[token, 0, 1, My, [sentence -> 0], []], [token...|[[token, 0, 1, My, [sentence -> 0], []], [token...|[[token, 3, 6, life, [sentence -> 0], []], [tok...|[[document, 0, 22, life Russia interesting, [se...|\n",
            "|John and Peter are brothers. However they don't...|[[document, 0, 76, John and Peter are brothers....|[[document, 0, 27, John and Peter are brothers....|[[token, 0, 3, John, [sentence -> 0], []], [tok...|[[token, 0, 3, John, [sentence -> 0], []], [tok...|[[token, 0, 3, John, [sentence -> 0], []], [tok...|[[document, 0, 18, John Peter brothers, [senten...|\n",
            "|Lucas Nogal Dunbercker is no longer happy. He h...|[[document, 0, 67, Lucas Nogal Dunbercker is no...|[[document, 0, 41, Lucas Nogal Dunbercker is no...|[[token, 0, 4, Lucas, [sentence -> 0], []], [to...|[[token, 0, 4, Lucas, [sentence -> 0], []], [to...|[[token, 0, 4, Lucas, [sentence -> 0], []], [to...|[[document, 0, 34, Lucas Nogal Dunbercker longe...|\n",
            "|Europe is very culture rich. There are huge chu...|[[document, 0, 68, Europe is very culture rich....|[[document, 0, 27, Europe is very culture rich....|[[token, 0, 5, Europe, [sentence -> 0], []], [t...|[[token, 0, 5, Europe, [sentence -> 0], []], [t...|[[token, 0, 5, Europe, [sentence -> 0], []], [t...|[[document, 0, 18, Europe culture rich, [senten...|\n",
            "+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c5w1HkiDKn3"
      },
      "source": [
        "# if we use TokenAssembler().setPreservePosition(True), the original borders will be preserved (dropped & unwanted chars will be replaced by spaces)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b7PUxa7DKhH",
        "outputId": "71ceedc4-ab13-4357-bfd4-f6dd12f0388a"
      },
      "source": [
        "result.select(\"assembled\").take(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(assembled=[Row(annotatorType='document', begin=0, end=16, result='Peter good person', metadata={'sentence': '0'}, embeddings=[])])]"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3Xq3J7UDKY4",
        "outputId": "12d9b60d-8918-496a-917f-756964cbf83b"
      },
      "source": [
        "result.select(\"text\", F.explode(\"assembled.result\").alias(\"cleaned_text\")).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------------------------+-----------------------------------+\n",
            "|text                                                                         |cleaned_text                       |\n",
            "+-----------------------------------------------------------------------------+-----------------------------------+\n",
            "|Peter is a very good person.                                                 |Peter good person                  |\n",
            "|My life in Russia is very interesting.                                       |life Russia interesting            |\n",
            "|John and Peter are brothers. However they don't support each other that much.|John Peter brothers                |\n",
            "|John and Peter are brothers. However they don't support each other that much.|However dont support much          |\n",
            "|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |Lucas Nogal Dunbercker longer happy|\n",
            "|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |good car though                    |\n",
            "|Europe is very culture rich. There are huge churches! and big houses!        |Europe culture rich                |\n",
            "|Europe is very culture rich. There are huge churches! and big houses!        |huge churches                      |\n",
            "|Europe is very culture rich. There are huge churches! and big houses!        |big houses                         |\n",
            "+-----------------------------------------------------------------------------+-----------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "2_Vhr-4qEZTu",
        "outputId": "638994aa-da02-4301-9785-42e06d6b56db"
      },
      "source": [
        "import pandas as pd\n",
        "result.select(\"text\", F.explode(\"assembled.result\").alias(\"cleaned_text\")).toPandas()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Peter is a very good person.</td>\n",
              "      <td>Peter good person</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>My life in Russia is very interesting.</td>\n",
              "      <td>life Russia interesting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>John and Peter are brothers. However they don'...</td>\n",
              "      <td>John Peter brothers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>John and Peter are brothers. However they don'...</td>\n",
              "      <td>However dont support much</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Lucas Nogal Dunbercker is no longer happy. He ...</td>\n",
              "      <td>Lucas Nogal Dunbercker longer happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Lucas Nogal Dunbercker is no longer happy. He ...</td>\n",
              "      <td>good car though</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Europe is very culture rich. There are huge ch...</td>\n",
              "      <td>Europe culture rich</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Europe is very culture rich. There are huge ch...</td>\n",
              "      <td>huge churches</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Europe is very culture rich. There are huge ch...</td>\n",
              "      <td>big houses</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text                         cleaned_text\n",
              "0                       Peter is a very good person.                    Peter good person\n",
              "1             My life in Russia is very interesting.              life Russia interesting\n",
              "2  John and Peter are brothers. However they don'...                  John Peter brothers\n",
              "3  John and Peter are brothers. However they don'...            However dont support much\n",
              "4  Lucas Nogal Dunbercker is no longer happy. He ...  Lucas Nogal Dunbercker longer happy\n",
              "5  Lucas Nogal Dunbercker is no longer happy. He ...                      good car though\n",
              "6  Europe is very culture rich. There are huge ch...                  Europe culture rich\n",
              "7  Europe is very culture rich. There are huge ch...                        huge churches\n",
              "8  Europe is very culture rich. There are huge ch...                           big houses"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jwlXSO9EZME",
        "outputId": "f406bf7d-c09e-4898-b962-eb6819326953"
      },
      "source": [
        "result.withColumn(\n",
        "    \"tmp\", \n",
        "    F.explode(\"assembled\"))\\\n",
        "    .select(\"tmp.*\").select(\"begin\", \"end\", \"result\", \"metadata.sentence\").show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+-----------------------------------+--------+\n",
            "|begin|end|result                             |sentence|\n",
            "+-----+---+-----------------------------------+--------+\n",
            "|0    |16 |Peter good person                  |0       |\n",
            "|0    |22 |life Russia interesting            |0       |\n",
            "|0    |18 |John Peter brothers                |0       |\n",
            "|29   |53 |However dont support much          |1       |\n",
            "|0    |34 |Lucas Nogal Dunbercker longer happy|0       |\n",
            "|43   |57 |good car though                    |1       |\n",
            "|0    |18 |Europe culture rich                |0       |\n",
            "|29   |41 |huge churches                      |1       |\n",
            "|54   |63 |big houses                         |2       |\n",
            "+-----+---+-----------------------------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1alEtgixEZEw",
        "outputId": "40d5a181-ee3d-4258-85dd-dfcf6e39275e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-----+---+--------------------+---------------+----------+\n",
            "|annotatorType|begin|end|              result|       metadata|embeddings|\n",
            "+-------------+-----+---+--------------------+---------------+----------+\n",
            "|     document|    0| 16|   Peter good person|[sentence -> 0]|        []|\n",
            "|     document|    0| 22|life Russia inter...|[sentence -> 0]|        []|\n",
            "|     document|    0| 18| John Peter brothers|[sentence -> 0]|        []|\n",
            "|     document|   29| 53|However dont supp...|[sentence -> 1]|        []|\n",
            "|     document|    0| 34|Lucas Nogal Dunbe...|[sentence -> 0]|        []|\n",
            "|     document|   43| 57|     good car though|[sentence -> 1]|        []|\n",
            "|     document|    0| 18| Europe culture rich|[sentence -> 0]|        []|\n",
            "|     document|   29| 41|       huge churches|[sentence -> 1]|        []|\n",
            "|     document|   54| 63|          big houses|[sentence -> 2]|        []|\n",
            "+-------------+-----+---+--------------------+---------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG36chLNQPCK"
      },
      "source": [
        "!wget -q https://raw.githubusercontent.com/mahavivo/vocabulary/master/lemmas/AntBNC_lemmas_ver_001.txt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAXTH8x_EwsM"
      },
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "    \n",
        "stemmer= Stemmer()\\\n",
        "    .setInputCols([\"token\"])\\\n",
        "    .setOutputCol(\"stem\")\n",
        "\n",
        "lemmatizer = Lemmatizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"lemma\") \\\n",
        "    .setDictionary(\"./AntBNC_lemmas_ver_001.txt\", value_delimiter =\"\\t\", key_delimiter = \"->\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omaeSld-Ewjz"
      },
      "source": [
        "nlpPipeline= Pipeline(stages=[ \n",
        "                              documentAssembler,\n",
        "                              tokenizer,\n",
        "                              stemmer,\n",
        "                              lemmatizer\n",
        "                              ])\n",
        "\n",
        "empty_df= spark.createDataFrame([[\" \"]]).toDF(\"text\")\n",
        "pipeline_model= nlpPipeline.fit(empty_df)\n",
        "\n",
        "result= pipeline_model.transform(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnR0qw_AEwbe",
        "outputId": "35692487-a6fb-4fc1-db25-71bd68184fc7"
      },
      "source": [
        "result.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|               token|                stem|               lemma|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|Peter is a very g...|[[document, 0, 27...|[[token, 0, 4, Pe...|[[token, 0, 4, pe...|[[token, 0, 4, Pe...|\n",
            "|My life in Russia...|[[document, 0, 37...|[[token, 0, 1, My...|[[token, 0, 1, my...|[[token, 0, 1, My...|\n",
            "|John and Peter ar...|[[document, 0, 76...|[[token, 0, 3, Jo...|[[token, 0, 3, jo...|[[token, 0, 3, Jo...|\n",
            "|Lucas Nogal Dunbe...|[[document, 0, 67...|[[token, 0, 4, Lu...|[[token, 0, 4, lu...|[[token, 0, 4, Lu...|\n",
            "|Europe is very cu...|[[document, 0, 68...|[[token, 0, 5, Eu...|[[token, 0, 5, eu...|[[token, 0, 5, Eu...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "8WicJTiUPeNn",
        "outputId": "7930db4e-8f6d-4b90-b913-a8543ab8af14"
      },
      "source": [
        "result_df= result.select(F.explode(F.arrays_zip(\"token.result\", \"stem.result\", \"lemma.result\")).alias(\"col\"))\\\n",
        "    .select(F.expr(\"col['0']\").alias(\"token\"),\n",
        "            F.expr(\"col['1']\").alias(\"stem\"),\n",
        "            F.expr(\"col['2']\").alias(\"lemma\")).toPandas()\n",
        "\n",
        "result_df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>stem</th>\n",
              "      <th>lemma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Peter</td>\n",
              "      <td>peter</td>\n",
              "      <td>Peter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is</td>\n",
              "      <td>i</td>\n",
              "      <td>be</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>very</td>\n",
              "      <td>veri</td>\n",
              "      <td>very</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>good</td>\n",
              "      <td>good</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>person</td>\n",
              "      <td>person</td>\n",
              "      <td>person</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>My</td>\n",
              "      <td>my</td>\n",
              "      <td>My</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>life</td>\n",
              "      <td>life</td>\n",
              "      <td>life</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>in</td>\n",
              "      <td>in</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    token    stem   lemma\n",
              "0   Peter   peter   Peter\n",
              "1      is       i      be\n",
              "2       a       a       a\n",
              "3    very    veri    very\n",
              "4    good    good    good\n",
              "5  person  person  person\n",
              "6       .       .       .\n",
              "7      My      my      My\n",
              "8    life    life    life\n",
              "9      in      in      in"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK6WEBHkUjry"
      },
      "source": [
        "## NGram Generator "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD2p_SV2D8FZ"
      },
      "source": [
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "import pyspark.sql.functions as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck5BfGmvPd8p"
      },
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "sentencer = SentenceDetector()\\\n",
        "    .setInputCols(['document'])\\\n",
        "    .setOutputCol('sentences')\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        "    .setInputCols([\"sentences\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "stemmer= Stemmer()\\\n",
        "    .setInputCols([\"token\"])\\\n",
        "    .setOutputCol(\"stem\")\n",
        "\n",
        "ngram= NGramGenerator()\\\n",
        "    .setInputCols([\"stem\"])\\\n",
        "    .setOutputCol(\"ngram\")\\\n",
        "    .setN(3)\\\n",
        "    .setDelimiter(\"_\")\\\n",
        "    .setEnableCumulative(True)\n",
        "\n",
        "nlpPipeline= Pipeline(stages=[ \n",
        "                              documentAssembler,\n",
        "                              sentencer,\n",
        "                              tokenizer,\n",
        "                              stemmer,\n",
        "                              ngram\n",
        "])\n",
        "\n",
        "empty_df= spark.createDataFrame([[\" \"]]).toDF(\"text\")\n",
        "pipeline_model= nlpPipeline.fit(empty_df)\n",
        "\n",
        "result= pipeline_model.transform(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OUJ7GQmDAz5",
        "outputId": "46f7e6b7-cfee-4818-b5a6-207de9e13233"
      },
      "source": [
        "result.select(\"ngram.result\").show(truncate=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------------------------------------------------------------------+\n",
            "|                                                                                              result|\n",
            "+----------------------------------------------------------------------------------------------------+\n",
            "|[peter, i, a, veri, good, person, ., peter_i, i_a, a_veri, veri_good, good_person, person_., pete...|\n",
            "|[my, life, in, russia, i, veri, interest, ., my_life, life_in, in_russia, russia_i, i_veri, veri_...|\n",
            "|[john, and, peter, ar, brother, ., john_and, and_peter, peter_ar, ar_brother, brother_., john_and...|\n",
            "|[luca, nogal, dunberck, i, no, longer, happi, ., luca_nogal, nogal_dunberck, dunberck_i, i_no, no...|\n",
            "|[europ, i, veri, cultur, rich, ., europ_i, i_veri, veri_cultur, cultur_rich, rich_., europ_i_veri...|\n",
            "+----------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ek_M93R7Jazr"
      },
      "source": [
        "### Text Matcher (Entity Extractor)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2_IJE1fF8VQ",
        "outputId": "e6c6aec7-8b51-4f89-a13b-ec57ee66d1a2"
      },
      "source": [
        "entity_extractor= TextMatcher()\\\n",
        "      .setInputCols([\"document\", \"token\"])\\\n",
        "      .setOutputCol(\"matched_entities\")\n",
        "\n",
        "entity_extractor.extractParamMap()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{Param(parent='TextMatcher_23f4f952ec5f', name='caseSensitive', doc='whether to match regardless of case. Defaults true'): True,\n",
              " Param(parent='TextMatcher_23f4f952ec5f', name='inputCols', doc='previous annotations columns, if renamed'): ['document',\n",
              "  'token'],\n",
              " Param(parent='TextMatcher_23f4f952ec5f', name='lazyAnnotator', doc='Whether this AnnotatorModel acts as lazy in RecursivePipelines'): False,\n",
              " Param(parent='TextMatcher_23f4f952ec5f', name='mergeOverlapping', doc='whether to merge overlapping matched chunks. Defaults false'): False,\n",
              " Param(parent='TextMatcher_23f4f952ec5f', name='outputCol', doc='output annotation column. can be left default.'): 'matched_entities'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fejscbafF_f0"
      },
      "source": [
        "! wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_train.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSUxX1hLF_XC",
        "outputId": "bada33be-17b1-4544-e5fe-e1bc9aa12231"
      },
      "source": [
        "news_df= spark.read\\\n",
        "      .option(\"header\", True)\\\n",
        "      .csv(\"/content/news_category_train.csv\")\n",
        "\n",
        "news_df.show(5, truncate=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------------------------------------+\n",
            "|category|                                       description|\n",
            "+--------+--------------------------------------------------+\n",
            "|Business| Short sellers, Wall Street's dwindling band of...|\n",
            "|Business| Private investment firm Carlyle Group, which h...|\n",
            "|Business| Soaring crude prices plus worries about the ec...|\n",
            "|Business| Authorities have halted oil export flows from ...|\n",
            "|Business| Tearaway world oil prices, toppling records an...|\n",
            "+--------+--------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-z-YUJSF_Pa"
      },
      "source": [
        "#writing the target entities to the txt file\n",
        "entities = ['Wall Street', 'USD', 'stock', 'NYSE']\n",
        "\n",
        "with open(\"financial_entities.txt\", \"w\") as f:\n",
        "  for i in entities:\n",
        "    f.write(i+ \"\\n\")\n",
        "\n",
        "entities = ['soccer', 'world cup', 'Messi', 'FC Barcelona']\n",
        "with open(\"sport_entities.txt\", \"w\") as f:\n",
        "  for i in entities:\n",
        "    f.write(i+ \"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNj5sKA0F_Hq"
      },
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"description\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "financial_entity_extractor= TextMatcher()\\\n",
        "    .setInputCols([\"document\", \"token\"])\\\n",
        "    .setOutputCol(\"financial_entities\")\\\n",
        "    .setCaseSensitive(False)\\\n",
        "    .setEntities(\"financial_entities.txt\")\\\n",
        "    .setEntityValue(\"financial_entity\")\n",
        "\n",
        "sport_entity_extractor=TextMatcher()\\\n",
        "    .setInputCols([\"document\", \"token\"])\\\n",
        "    .setOutputCol(\"sport_entities\")\\\n",
        "    .setCaseSensitive(False)\\\n",
        "    .setEntities(\"sport_entities.txt\")\\\n",
        "    .setEntityValue(\"sport_entity\")\n",
        "\n",
        "nlpPipeline= Pipeline(stages= [ \n",
        "                               documentAssembler,\n",
        "                               tokenizer,\n",
        "                               financial_entity_extractor,\n",
        "                               sport_entity_extractor\n",
        "])\n",
        "\n",
        "empty_df= spark.createDataFrame([[\" \"]]).toDF(\"description\")\n",
        "pipeline_model= nlpPipeline.fit(empty_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GthMUnXBJuhK"
      },
      "source": [
        "result= pipeline_model.transform(news_df)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_r1-J36NFlN",
        "outputId": "f8ef8982-6cfa-49fd-fe37-478f139fb558"
      },
      "source": [
        "result.show(5, truncate=40)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------------------------------------+----------------------------------------+----------------------------------------+----------------------------------------+--------------+\n",
            "|category|                             description|                                document|                                   token|                      financial_entities|sport_entities|\n",
            "+--------+----------------------------------------+----------------------------------------+----------------------------------------+----------------------------------------+--------------+\n",
            "|Business| Short sellers, Wall Street's dwindli...|[[document, 0, 84,  Short sellers, Wa...|[[token, 1, 5, Short, [sentence -> 0]...|                                      []|            []|\n",
            "|Business| Private investment firm Carlyle Grou...|[[document, 0, 204,  Private investme...|[[token, 1, 7, Private, [sentence -> ...|                                      []|            []|\n",
            "|Business| Soaring crude prices plus worries ab...|[[document, 0, 174,  Soaring crude pr...|[[token, 1, 7, Soaring, [sentence -> ...|[[chunk, 112, 116, stock, [entity -> ...|            []|\n",
            "|Business| Authorities have halted oil export f...|[[document, 0, 185,  Authorities have...|[[token, 1, 11, Authorities, [sentenc...|                                      []|            []|\n",
            "|Business| Tearaway world oil prices, toppling ...|[[document, 0, 154,  Tearaway world o...|[[token, 1, 8, Tearaway, [sentence ->...|                                      []|            []|\n",
            "+--------+----------------------------------------+----------------------------------------+----------------------------------------+----------------------------------------+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2WS3G86JuX4",
        "outputId": "0e6f8630-5f2e-4af5-dbf2-1a93e3e345ce"
      },
      "source": [
        "result.select(\"financial_entities.result\", \"sport_entities.result\").take(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(result=[], result=[]), Row(result=[], result=[])]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoCHhT3kJuOq",
        "outputId": "9b07222b-a19c-470d-fa88-376170bfbb6c"
      },
      "source": [
        "result.select(\"description\",\"financial_entities.result\", \"sport_entities.result\")\\\n",
        "  .toDF(\"description\", \"financial_matches\", \"sport_matches\").filter((F.size(\"financial_matches\")>1) | (F.size(\"sport_matches\")>1))\\\n",
        "  .show(truncate=70)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------------------------------------+----------------------------------+-------------------+\n",
            "|                                                           description|                 financial_matches|      sport_matches|\n",
            "+----------------------------------------------------------------------+----------------------------------+-------------------+\n",
            "|\"Company launched the biggest electronic auction of stock in Wall S...|              [stock, Wall Street]|                 []|\n",
            "|Google, Inc. significantly cut the expected share price for its ini...|                    [stock, stock]|                 []|\n",
            "|Google, Inc. significantly cut the expected share price this mornin...|                    [stock, stock]|                 []|\n",
            "| Shares of Air Canada  (AC.TO) fell by more than half on Wednesday,...|                    [Stock, stock]|                 []|\n",
            "|Stock prices are lower in moderate trading. The Dow Jones Industria...|                    [Stock, Stock]|                 []|\n",
            "|The bad news just keeps pouring in for mutual fund manager Janus Ca...|                      [NYSE, NYSE]|                 []|\n",
            "|  Shaun Wright Phillips scored in his international debut as Englan...|                                []|[soccer, World Cup]|\n",
            "|NEWCASTLE, ENGLAND - England deservedly beat Ukraine 3-0 today in t...|                                []|[soccer, World Cup]|\n",
            "|MONTREAL (Reuters) - Shares of Air Canada (AC.TO: Quote, Profile, R...|                    [Stock, stock]|                 []|\n",
            "|\"SAN JOSE, California - On the cusp of its voyage into public tradi...|[stock, Wall Street, stock, Stock]|                 []|\n",
            "|\"Shortly before noon today, Google Inc. stock began trading under t...|                    [stock, stock]|                 []|\n",
            "|roundup Plus: EA to take World Cup soccer to Xbox...IBM chalks up t...|                                []|[World Cup, soccer]|\n",
            "|The U.S. Securities and Exchange Commission yesterday approved Goog...|                    [stock, stock]|                 []|\n",
            "|After a bumpy ride toward becoming a publicly traded company, Googl...|                    [stock, stock]|                 []|\n",
            "|In the most highly anticipated Wall Street debut since the heady da...|              [Wall Street, stock]|                 []|\n",
            "|NEW YORK Despite voluble skepticism among investors, Google #39;s s...|                    [stock, stock]|                 []|\n",
            "|If only the rest of my investments worked out this way. One week ag...|                    [stock, stock]|                 []|\n",
            "| U.S. stocks to watch: GOOGLE INC. (GOOG.O) Google shares jumped 18...|                    [stock, stock]|                 []|\n",
            "|\" U.S. stocks to watch: GOOGLE INC.  &lt;A HREF=\"\"http://www.invest...|                    [stock, stock]|                 []|\n",
            "|roundup Plus: KDE updates Linux desktop...EA to take World Cup socc...|                                []|[World Cup, soccer]|\n",
            "+----------------------------------------------------------------------+----------------------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "p4aE0agTLCWL",
        "outputId": "9fba7378-d3b9-44cc-a4da-8c00389ab428"
      },
      "source": [
        "result_df= result.select(F.explode(F.arrays_zip(\"financial_entities.result\", \"financial_entities.begin\", \"financial_entities.end\")).alias(\"col\"))\\\n",
        "    .select(F.expr(\"col['0']\").alias(\"financial_chunk\"),\n",
        "            F.expr(\"col['1']\").alias(\"begin\"), \n",
        "            F.expr(\"col['2']\").alias(\"end\")).toPandas()\n",
        "result_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>financial_chunk</th>\n",
              "      <th>begin</th>\n",
              "      <th>end</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>stock</td>\n",
              "      <td>112</td>\n",
              "      <td>116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>stock</td>\n",
              "      <td>114</td>\n",
              "      <td>118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>stock</td>\n",
              "      <td>45</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>stock</td>\n",
              "      <td>126</td>\n",
              "      <td>130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>stock</td>\n",
              "      <td>188</td>\n",
              "      <td>192</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  financial_chunk  begin  end\n",
              "0           stock    112  116\n",
              "1           stock    114  118\n",
              "2           stock     45   49\n",
              "3           stock    126  130\n",
              "4           stock    188  192"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBHMUrSzLCNK"
      },
      "source": [
        "! wget -q\thttps://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/pubmed/pubmed-sample.csv\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6JEmfuPLCEk",
        "outputId": "4de4d095-821a-4e8f-a85f-511caf13ea34"
      },
      "source": [
        "pubMedDf= spark.read\\\n",
        "  .option(\"header\", True)\\\n",
        "  .csv(\"/content/pubmed-sample.csv\")\\\n",
        "  .filter(\"AB IS NOT null\")\\\n",
        "  .withColumnRenamed(\"AB\", \"text\")\\\n",
        "  .drop(\"TI\")\n",
        "\n",
        "pubMedDf.show(truncate=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------+\n",
            "|                                              text|\n",
            "+--------------------------------------------------+\n",
            "|The human KCNJ9 (Kir 3.3, GIRK3) is a member of...|\n",
            "|BACKGROUND: At present, it is one of the most i...|\n",
            "|OBJECTIVE: To investigate the relationship betw...|\n",
            "|Combined EEG/fMRI recording has been used to lo...|\n",
            "|Kohlschutter syndrome is a rare neurodegenerati...|\n",
            "|Statistical analysis of neuroimages is commonly...|\n",
            "|The synthetic DOX-LNA conjugate was characteriz...|\n",
            "|Our objective was to compare three different me...|\n",
            "|We conducted a phase II study to assess the eff...|\n",
            "|\"Monomeric sarcosine oxidase (MSOX) is a flavoe...|\n",
            "|We presented the tachinid fly Exorista japonica...|\n",
            "|The literature dealing with the water conductin...|\n",
            "|A novel approach to synthesize chitosan-O-isopr...|\n",
            "|An HPLC-ESI-MS-MS method has been developed for...|\n",
            "|The localizing and lateralizing values of eye a...|\n",
            "|OBJECTIVE: To evaluate the effectiveness and ac...|\n",
            "|For the construction of new combinatorial libra...|\n",
            "|We report the results of a screen for genetic a...|\n",
            "|Intraparenchymal pericatheter cyst is rarely re...|\n",
            "|It is known that patients with Klinefelter's sy...|\n",
            "+--------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A38Q1LxZOGPu"
      },
      "source": [
        "rules = '''\n",
        "renal\\s\\w+, started with 'renal'\n",
        "cardiac\\s\\w+, started with 'cardiac'\n",
        "\\w*ly\\b, ending with 'ly'\n",
        "\\S*\\d+\\S*, match any word that contains numbers\n",
        "(\\d+).?(\\d*)\\s*(mg|ml|g), match medication metrics\n",
        "'''\n",
        "\n",
        "with open(\"regex_rules\", \"w\") as f:\n",
        "  f.write(rules)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Muj_zKiOGG4"
      },
      "source": [
        "documentAssembler= DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "regex_matcher= RegexMatcher()\\\n",
        "  .setInputCols([\"document\"])\\\n",
        "  .setStrategy(\"MATCH_ALL\")\\\n",
        "  .setOutputCol(\"matched_regex\")\\\n",
        "  .setExternalRules(\"/content/regex_rules\", delimiter=\",\")\n",
        "\n",
        "nlpPipeline= Pipeline(stages= [ \n",
        "                               documentAssembler,\n",
        "                               regex_matcher\n",
        "])\n",
        "\n",
        "empty_df= spark.createDataFrame([[\" \"]]).toDF(\"text\")\n",
        "pipeline_model= nlpPipeline.fit(empty_df)\n",
        "result= pipeline_model.transform(pubMedDf)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODcxY-w_SktS",
        "outputId": "dc714e45-bf35-4188-d369-85dba2622bde"
      },
      "source": [
        "result.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "|                text|            document|       matched_regex|\n",
            "+--------------------+--------------------+--------------------+\n",
            "|The human KCNJ9 (...|[[document, 0, 95...|[[chunk, 72, 79, ...|\n",
            "|BACKGROUND: At pr...|[[document, 0, 14...|[[chunk, 143, 152...|\n",
            "|OBJECTIVE: To inv...|[[document, 0, 15...|[[chunk, 805, 817...|\n",
            "|Combined EEG/fMRI...|[[document, 0, 16...|[[chunk, 335, 342...|\n",
            "|Kohlschutter synd...|[[document, 0, 25...|[[chunk, 220, 225...|\n",
            "|Statistical analy...|[[document, 0, 10...|[[chunk, 12, 16, ...|\n",
            "|The synthetic DOX...|[[document, 0, 57...|[[chunk, 150, 157...|\n",
            "|Our objective was...|[[document, 0, 24...|[[chunk, 397, 401...|\n",
            "|We conducted a ph...|[[document, 0, 14...|[[chunk, 855, 859...|\n",
            "|\"Monomeric sarcos...|[[document, 0, 14...|[[chunk, 58, 63, ...|\n",
            "|We presented the ...|[[document, 0, 12...|[[chunk, 26, 28, ...|\n",
            "|The literature de...|[[document, 0, 16...|[[chunk, 427, 435...|\n",
            "|A novel approach ...|[[document, 0, 64...|[[chunk, 168, 178...|\n",
            "|An HPLC-ESI-MS-MS...|[[document, 0, 90...|[[chunk, 268, 286...|\n",
            "|The localizing an...|[[document, 0, 72...|[[chunk, 324, 328...|\n",
            "|OBJECTIVE: To eva...|[[document, 0, 13...|[[chunk, 471, 476...|\n",
            "|For the construct...|[[document, 0, 32...|[[chunk, 212, 216...|\n",
            "|We report the res...|[[document, 0, 13...|[[chunk, 325, 328...|\n",
            "|Intraparenchymal ...|[[document, 0, 10...|[[chunk, 38, 43, ...|\n",
            "|It is known that ...|[[document, 0, 34...|                  []|\n",
            "+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "fUJJn14vSkkS",
        "outputId": "c4bfdf50-c829-4abd-b5da-99d8811d6977"
      },
      "source": [
        "result.select(\"text\", \"matched_regex.result\")\\\n",
        "    .toDF(\"text\", \"regex\").filter(F.size(\"regex\")>1)\\\n",
        "    .show(truncate=80)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-efd92f36c265>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"matched_regex.result\"\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;34m.\u001b[0m\u001b[0mtoDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"regex\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"regex\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4j0B53qSkaS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dca916e-cf86-4c2b-c89c-db21f58021b3"
      },
      "source": [
        "MultiDateMatcher().extractParamMap()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{Param(parent='MultiDateMatcher_54f0349cc579', name='dateFormat', doc='desired format for dates extracted'): 'yyyy/MM/dd',\n",
              " Param(parent='MultiDateMatcher_54f0349cc579', name='defaultDayWhenMissing', doc='which day to set when it is missing from parsed input'): 1,\n",
              " Param(parent='MultiDateMatcher_54f0349cc579', name='lazyAnnotator', doc='Whether this AnnotatorModel acts as lazy in RecursivePipelines'): False,\n",
              " Param(parent='MultiDateMatcher_54f0349cc579', name='readMonthFirst', doc='Whether to parse july 07/05/2015 or as 05/07/2015'): True}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VovYQUa90Y4M"
      },
      "source": [
        "documentAssembler= DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "date_matcher= MultiDateMatcher()\\\n",
        "    .setInputCols([\"document\"])\\\n",
        "    .setOutputCol(\"dates\")\\\n",
        "    .setDateFormat(\"yyyy/mm/dd\")\n",
        "\n",
        "date_pipeline= Pipeline(stages=[ \n",
        "                                documentAssembler,\n",
        "                                date_matcher\n",
        "])\n",
        "\n",
        "date_df= spark.createDataFrame([['I saw him yesterday and he told me that he will visit us next week']]).toDF(\"text\")\n",
        "pipeline_model= date_pipeline.fit(date_df)\n",
        "result=pipeline_model.transform(date_df)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pqh2KlVN39Nu",
        "outputId": "d46be9c2-8c13-4a35-c48c-fab0d2e8dcc1"
      },
      "source": [
        "result.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "|                text|            document|               dates|\n",
            "+--------------------+--------------------+--------------------+\n",
            "|I saw him yesterd...|[[document, 0, 65...|[[date, 57, 65, 2...|\n",
            "+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Z0dMZKR0Yx-",
        "outputId": "67b9628f-e534-4b91-89a1-143f2b28477a"
      },
      "source": [
        "result.select(\"dates.result\").show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------+\n",
            "|result                  |\n",
            "+------------------------+\n",
            "|[2021/08/04, 2021/08/26]|\n",
            "+------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Boruf-jOF9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "066f265b-5ca6-42f9-a531-2c54d1b9b7b3"
      },
      "source": [
        "result.select(\"document.result\", \"dates.result\")\\\n",
        "    .toDF(\"text\", \"dates\").show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------+------------------------+\n",
            "|text                                                                |dates                   |\n",
            "+--------------------------------------------------------------------+------------------------+\n",
            "|[I saw him yesterday and he told me that he will visit us next week]|[2021/10/04, 2021/10/26]|\n",
            "+--------------------------------------------------------------------+------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NR2gqxD32tS"
      },
      "source": [
        "documentAssembler= DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "date_matcher= MultiDateMatcher()\\\n",
        "    .setInputCols([\"document\"])\\\n",
        "    .setOutputCol(\"dates\")\\\n",
        "    .setDateFormat(\"yyyy/mm/dd\")\n",
        "\n",
        "date_pipeline= Pipeline(stages=[ \n",
        "                                documentAssembler,\n",
        "                                date_matcher\n",
        "])\n",
        "\n",
        "date_df= spark.createDataFrame([['I saw him yesterday and he told me that he will visit us next week.']]).toDF(\"text\")\n",
        "pipeline_model= date_pipeline.fit(date_df)\n",
        "result=pipeline_model.transform(date_df)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIudK9C532ju",
        "outputId": "3a0b6f4a-bec5-43e1-9339-abe7210f51ed"
      },
      "source": [
        "result.select(\"dates.result\").show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------+\n",
            "|result                  |\n",
            "+------------------------+\n",
            "|[2021/17/04, 2021/17/26]|\n",
            "+------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UlcklUU32Z4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}