{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFoUYsY5vEbK"
      },
      "source": [
        "# Sentiment Analysis\n",
        "### Using SparkNLP pre-trained sentimentdl model <br/>\n",
        "- Firstly, I've applied a few pre-processing steps. <br/>\n",
        "> Getting rid of undesired data. <br/>\n",
        "> Checking the null values and getting rid of them. <br/> \n",
        "> Spell Checking <br/>\n",
        "> Cleaning stopwords.  <br/>\n",
        "- Then, I've started to create pipeline that includes Sparknlp annotators and models. \n",
        "> I've used **glove embedding** as the embedding. <br/>\n",
        "> I've used the sparknlp **sentimentdl_glove_imdb** pre-trained model as sentiment classifier. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51emSBZvtbJA",
        "outputId": "8f6c4440-154f-43b6-b299-166966401b16"
      },
      "source": [
        "! pip install -q pyspark==3.1.2 spark-nlp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 212.4 MB 58 kB/s \n",
            "\u001b[K     |████████████████████████████████| 122 kB 55.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 52.6 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_kFyn4xtzu1"
      },
      "source": [
        "import sparknlp \n",
        "spark= sparknlp.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD8OmaoxuqZP"
      },
      "source": [
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import * \n",
        "from pyspark.ml import Pipeline\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.ml.feature import SQLTransformer, StringIndexer\n",
        "from pyspark.sql.functions import explode, col, when, isnan, count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6xIuwYhvHrZ"
      },
      "source": [
        "df_train= spark.read\\\n",
        "    .option(\"header\", True)\\\n",
        "    .csv(\"/content/Train.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsFj-fnZzl0W",
        "outputId": "87027b4f-7fb5-44fe-9e7a-c1a090e8c205"
      },
      "source": [
        "df_train.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40000"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-ALPQAnvHo9",
        "outputId": "b1cce0e7-e4a2-4525-d579-049cff663b66"
      },
      "source": [
        "df_train.show(5, truncate=40)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------+----------------------------------------+\n",
            "|                                    text|                                   label|\n",
            "+----------------------------------------+----------------------------------------+\n",
            "|\"I grew up (b. 1965) watching and lov...| during lunch and after school. We al...|\n",
            "|When I put this movie in my DVD playe...|                                       0|\n",
            "|\"Why do people who do not know what a...| I'll put out my own movie and prove ...|\n",
            "|Even though I have great interest in ...|                                       0|\n",
            "|\"Im a die hard Dads Army fan and noth...|                                       1|\n",
            "+----------------------------------------+----------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfsPk_h91G57"
      },
      "source": [
        "Seems like there are some undesired values in 'label' column. We will only keep '0' and '1' values in 'label' colum, so we will get rid of undesired ones.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hyC9fx_vHmf",
        "outputId": "06988d83-7db9-4e0a-8cc3-dfb550735235"
      },
      "source": [
        "df_train.groupBy(\"label\").count().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|               label|count|\n",
            "+--------------------+-----+\n",
            "| so little substance|    1|\n",
            "| giving us a few ...|    1|\n",
            "| it´s instead a l...|    1|\n",
            "| a bunch of lonel...|    1|\n",
            "| \"\"La Noche del T...|    1|\n",
            "| \"\"Nightmare\"\" is...|    1|\n",
            "| says a character...|    1|\n",
            "| he has beautiful...|    1|\n",
            "| not even uninten...|    1|\n",
            "| you should get t...|    1|\n",
            "| as I'd thought i...|    1|\n",
            "|  and let's remember|    1|\n",
            "| for the simple r...|    1|\n",
            "| be a smartie. Co...|    1|\n",
            "| then this film i...|    1|\n",
            "|           the thief|    1|\n",
            "| the camera focus...|    1|\n",
            "| this independent...|    1|\n",
            "| almost anyone wo...|    1|\n",
            "| while others wil...|    1|\n",
            "+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFcv99_OwRbE",
        "outputId": "5eb4e5f2-e0d6-4af6-e1f7-5673b31782ab"
      },
      "source": [
        "df_train= df_train.filter((df_train[\"label\"]==0) | (df_train[\"label\"]==1))\n",
        "df_train.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22922"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brlkxrQG5HbM"
      },
      "source": [
        "Now, we will check whether there are null, NaN or blank values in dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_LlEumWaCwQ",
        "outputId": "37c0f162-bcd8-44d0-dd82-e1725142ce48"
      },
      "source": [
        "df_train.select([count(when(col(c).isNull() | \\\n",
        "                            isnan(c) | \\\n",
        "                            (col(c)== \" \"), c)).alias(c) for c in df_train.columns]).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "|text|label|\n",
            "+----+-----+\n",
            "|   0|    0|\n",
            "+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jd7QaIb1c70Q"
      },
      "source": [
        "As we see above, there are no null values. We can start building pipeline for sentiment analysis. <br/>\n",
        " Firstly, I will create annotators and models. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTT2vok03rJW",
        "outputId": "e9f6fff5-d22e-482a-d1c2-c7e8759a67c1"
      },
      "source": [
        "documentAssembler= DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer= Tokenizer()\\   #tokenizing\n",
        "    .setInputCols([\"document\"])\\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "spell_checker= ContextSpellCheckerModel.pretrained(\"spellcheck_dl\")\\   #correcting the misspellings in the text\n",
        "    .setInputCols([\"token\"])\\\n",
        "    .setOutputCol(\"spell_checked\")\n",
        "\n",
        "stopwords_cleaner= StopWordsCleaner.pretrained(\"stopwords_en\", \"en\")\\   #cleaning stopwords\n",
        "    .setInputCols([\"spell_checked\"])\\\n",
        "    .setOutputCol(\"cleaned\")\\\n",
        "    .setCaseSensitive(False)\n",
        "\n",
        "word_embedding= WordEmbeddingsModel.pretrained(\"glove_100d\")\\   #glove embedding\n",
        "    .setInputCols([\"document\",\"cleaned\"])\\\n",
        "    .setOutputCol(\"embeddings\")\n",
        "\n",
        "sentence_embedding= SentenceEmbeddings()\\     #sentence embedding by using embedded tokens\n",
        "    .setInputCols([\"document\" ,\"embeddings\"])\\\n",
        "    .setOutputCol(\"sentence_embeddings\")\\\n",
        "    .setPoolingStrategy(\"AVERAGE\")\n",
        "\n",
        "classifier= SentimentDLModel.pretrained(\"sentimentdl_glove_imdb\")\\   #pre-trained sentientdl model\n",
        "    .setInputCols([\"sentence_embeddings\"])\\\n",
        "    .setOutputCol(\"sentiment\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spellcheck_dl download started this may take some time.\n",
            "Approximate size to download 111.4 MB\n",
            "[OK!]\n",
            "stopwords_en download started this may take some time.\n",
            "Approximate size to download 2.9 KB\n",
            "[OK!]\n",
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n",
            "sentimentdl_glove_imdb download started this may take some time.\n",
            "Approximate size to download 8.7 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUKTCeJnYtOM"
      },
      "source": [
        "Now, It is time to putting all annotators and models into a pipeline and fitting with our dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs-hqBNm5VO9"
      },
      "source": [
        "nlp_pipeline= Pipeline(stages=[ \n",
        "                               documentAssembler,\n",
        "                               tokenizer,\n",
        "                               spell_checker,\n",
        "                               stopwords_cleaner,\n",
        "                               word_embedding,\n",
        "                               sentence_embedding,\n",
        "                               classifier\n",
        "])\n",
        "\n",
        "model= nlp_pipeline.fit(df_train.limit(200))\n",
        "result= model.transform(df_train.limit(200))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdvYWJ2W5VMU",
        "outputId": "65cf3090-3ca7-401b-a6db-2f5b752a3a85"
      },
      "source": [
        "result.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['text',\n",
              " 'label',\n",
              " 'document',\n",
              " 'token',\n",
              " 'spell_checked',\n",
              " 'cleaned',\n",
              " 'embeddings',\n",
              " 'sentence_embeddings',\n",
              " 'sentiment']"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLjcLHO-ZAld"
      },
      "source": [
        "The sentiment results of each tweet are like following. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQnyj8M4nHtU",
        "outputId": "edff5d5b-c4b7-4559-9a0d-a5ed9f36cc83"
      },
      "source": [
        "result.select(\"sentence_embeddings.result\", \"sentiment.result\").show(5, truncate=140)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
            "|                                                                                                                                      result|result|\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
            "|[When I put this movie in my DVD player, and sat down with a coke and some chips, I had some expectations. I was hoping that this movie w...| [pos]|\n",
            "|[Even though I have great interest in Biblical movies, I was bored to death every minute of the movie. Everything is bad. The movie is to...| [neg]|\n",
            "|[\"Im a die hard Dads Army fan and nothing will ever change that. I got all the tapes, DVD's and audiobooks and every time i watch/listen ...| [pos]|\n",
            "|[A terrible movie as everyone has said. What made me laugh was the cameo appearance by Scott McNealy, giving an award to one of the murde...| [neg]|\n",
            "|[It may be the remake of 1987 Autumn's Tale after eleven years, as the director Mabel Cheung claimed. Mabel employs rock music as the med...| [pos]|\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}