{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ner_visualization_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahvOzzVCP17h"
      },
      "source": [
        "#Named Entity Visualization\n",
        "In this notebook, we first create NER pipeline and then inspect the basic method results and SparkNLP Ner Visualizer results. So, we will have a chance to see the power of the visualizer.  <br/>\n",
        "\n",
        "Firstly, setting up packages and libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1K621YoN7iID",
        "outputId": "8eac0db4-cdf3-4121-ad63-94aed70a47d4"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/colab_setup.sh -O - | bash"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-23 16:14:49--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1608 (1.6K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "\r-                     0%[                    ]       0  --.-KB/s               \r-                   100%[===================>]   1.57K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-23 16:14:50 (33.1 MB/s) - written to stdout [1608/1608]\n",
            "\n",
            "setup Colab for PySpark 3.0.2 and Spark NLP 3.1.0\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [69.5 kB]\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [753 kB]\n",
            "Hit:14 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [630 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,396 kB]\n",
            "Hit:19 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,835 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,434 kB]\n",
            "Get:16 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,213 kB]\n",
            "Get:23 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,809 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [665 kB]\n",
            "Get:25 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [926 kB]\n",
            "Get:26 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Fetched 11.6 MB in 8s (1,437 kB/s)\n",
            "Reading package lists... Done\n",
            "tar: spark-3.0.2-bin-hadoop2.7.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "\u001b[K     |████████████████████████████████| 204.8 MB 44 kB/s \n",
            "\u001b[K     |████████████████████████████████| 44 kB 2.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 47.2 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGfYUKdK7nRv"
      },
      "source": [
        "import sparknlp\n",
        "spark= sparknlp.start()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAxU2BEG7rRf"
      },
      "source": [
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import functions as F\n",
        "import pandas as pd"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZl5ERyBQFhl"
      },
      "source": [
        "Now, I will create annotators and models and put them into a pipeline. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpRITnaY8iI6",
        "outputId": "67ab2dcd-acfc-4a62-f51c-a4b27819810c"
      },
      "source": [
        "documentAssembler= DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer= Tokenizer()\\\n",
        "    .setInputCols([\"document\"])\\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "spell_checker= ContextSpellCheckerModel.pretrained()\\\n",
        "    .setInputCols(\"token\")\\\n",
        "    .setOutputCol(\"checked\")\n",
        "\n",
        "word_embedding= WordEmbeddingsModel.pretrained(\"glove_100d\")\\\n",
        "    .setInputCols([\"document\", \"checked\"])\\\n",
        "    .setOutputCol(\"embeddings\")\n",
        "\n",
        "onto_ner = NerDLModel.pretrained(\"onto_100\", 'en') \\\n",
        "          .setInputCols([\"document\", \"checked\", \"embeddings\"]) \\\n",
        "          .setOutputCol(\"ner\")\n",
        "\n",
        "ner_converter= NerConverter()\\\n",
        "    .setInputCols([\"document\", \"checked\", \"ner\"])\\\n",
        "    .setOutputCol(\"entities\")\n",
        "\n",
        "nlp_pipeline= Pipeline(stages=[ \n",
        "                               documentAssembler,\n",
        "                               tokenizer,\n",
        "                               spell_checker,\n",
        "                               word_embedding,\n",
        "                               onto_ner,\n",
        "                               ner_converter\n",
        "])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spellcheck_dl download started this may take some time.\n",
            "Approximate size to download 111.4 MB\n",
            "[OK!]\n",
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n",
            "onto_100 download started this may take some time.\n",
            "Approximate size to download 13.5 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6F7mfh9nQOzV"
      },
      "source": [
        "Fitting the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4G8JvRH8iGb"
      },
      "source": [
        "empty_df= spark.createDataFrame([[\" \"]]).toDF(\"text\")\n",
        "model= nlp_pipeline.fit(empty_df)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjR0mE-pKhnc"
      },
      "source": [
        "example= [\"\"\"Wesley Sneijder is a great player and he has numbers of achievements such as a World Cup, a UEFA Champions League title in his career.\n",
        "             However, he declared his retirement last week on BBCSport livestream\"\"\"] #sample text data\n",
        "df= spark.createDataFrame([example]).toDF(\"text\")"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hURJ0wKymTTF"
      },
      "source": [
        "By the classic method we transform the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MB2z_EVm8vew",
        "outputId": "fafd72a1-732b-4096-c824-84d1bf0ed01e"
      },
      "source": [
        "ner_result= model.transform(df)\n",
        "ner_result.columns"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['text', 'document', 'token', 'checked', 'embeddings', 'ner', 'entities']"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D_ED43DmkPB"
      },
      "source": [
        "Inspecting the results in classic method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pngPzx0Q8vbz",
        "outputId": "fef959a5-eb6b-4e4c-e437-3d0aef99af39"
      },
      "source": [
        "result_df=  ner_result.select(F.explode(F.arrays_zip(\"token.result\", \"checked.result\", \"ner.result\", \"entities.result\")).alias(\"col\"))\\\n",
        "                .select(F.expr(\"col['0']\").alias(\"token\"),\n",
        "                        F.expr(\"col['1']\").alias(\"spell_checked\"),\n",
        "                        F.expr(\"col['2']\").alias(\"ner\"),\n",
        "                        F.expr(\"col['3']\").alias(\"entities\"))\n",
        "result_df.show(truncate=False)"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------------+--------+---------------------+\n",
            "|token       |spell_checked|ner     |entities             |\n",
            "+------------+-------------+--------+---------------------+\n",
            "|Wesley      |Wesley       |B-PERSON|Wesley Sneijder      |\n",
            "|Sneijder    |Snider       |I-PERSON|a World Cup          |\n",
            "|is          |is           |O       |UEFA Champions League|\n",
            "|a           |a            |O       |last week            |\n",
            "|great       |great        |O       |BBCSport             |\n",
            "|player      |player       |O       |null                 |\n",
            "|and         |and          |O       |null                 |\n",
            "|he          |he           |O       |null                 |\n",
            "|has         |has          |O       |null                 |\n",
            "|numbers     |numbers      |O       |null                 |\n",
            "|of          |of           |O       |null                 |\n",
            "|achievements|achievements |O       |null                 |\n",
            "|such        |such         |O       |null                 |\n",
            "|as          |as           |O       |null                 |\n",
            "|a           |a            |B-EVENT |null                 |\n",
            "|World       |World        |I-EVENT |null                 |\n",
            "|Cup         |Cup          |I-EVENT |null                 |\n",
            "|,           |,            |O       |null                 |\n",
            "|a           |a            |O       |null                 |\n",
            "|UEFA        |SEA          |B-EVENT |null                 |\n",
            "+------------+-------------+--------+---------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rlh2ECaimqDx"
      },
      "source": [
        "We created pipeline as well as model and saw the results. <br/>\n",
        "Now, we will install **sparknlp display** package and see the result by using sparknlp **LightPipeine**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sbzc6KaoSFL"
      },
      "source": [
        "Creating LightPipeline and annotating it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9031q08RErqX",
        "outputId": "e3ac69cc-f073-42a8-ffcc-9edf35c046f4"
      },
      "source": [
        "lp= LightPipeline(model)\n",
        "lp_result= lp.fullAnnotate(example)[0]\n",
        "lp_result.keys()"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['entities', 'checked', 'document', 'token', 'ner', 'embeddings'])"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfY4PS6OoeT_"
      },
      "source": [
        "Finally, creating visualizer and see the awesome result. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1vrWjwnpAyE"
      },
      "source": [
        "!pip install spark-nlp-display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQdZ7sZ6pAI7"
      },
      "source": [
        "from sparknlp_display import NerVisualizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "3RkNGIdXGMGH",
        "outputId": "0173eb53-872f-4869-ba3c-1b9e3f96fa96"
      },
      "source": [
        "visualizer= NerVisualizer()\n",
        "visualizer.display(lp_result,\n",
        "                   label_col=\"entities\",\n",
        "                   document_col=\"document\")"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n",
              "    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n",
              "    \n",
              "    .spark-nlp-display-scroll-entities {\n",
              "        border: 1px solid #E7EDF0;\n",
              "        border-radius: 3px;\n",
              "        text-align: justify;\n",
              "        \n",
              "    }\n",
              "    .spark-nlp-display-scroll-entities span {  \n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #536B76;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-entity-wrapper{\n",
              "    \n",
              "        display: inline-grid;\n",
              "        text-align: center;\n",
              "        border-radius: 4px;\n",
              "        margin: 0 2px 5px 2px;\n",
              "        padding: 1px\n",
              "    }\n",
              "    .spark-nlp-display-entity-name{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        background: #f1f2f3;\n",
              "        border-width: medium;\n",
              "        text-align: center;\n",
              "        \n",
              "        font-weight: 400;\n",
              "        \n",
              "        border-radius: 5px;\n",
              "        padding: 2px 5px;\n",
              "        display: block;\n",
              "        margin: 3px 2px;\n",
              "    \n",
              "    }\n",
              "    .spark-nlp-display-entity-type{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #ffffff;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        text-transform: uppercase;\n",
              "        \n",
              "        font-weight: 500;\n",
              "\n",
              "        display: block;\n",
              "        padding: 3px 5px;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-entity-resolution{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #ffffff;\n",
              "        font-family: 'Vistol Regular', sans-serif !important;\n",
              "        \n",
              "        text-transform: uppercase;\n",
              "        \n",
              "        font-weight: 500;\n",
              "\n",
              "        display: block;\n",
              "        padding: 3px 5px;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-others{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        font-weight: 400;\n",
              "    }\n",
              "\n",
              "</style>\n",
              " <span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #1C2009\"><span class=\"spark-nlp-display-entity-name\">Wesley Sneijder </span><span class=\"spark-nlp-display-entity-type\">PERSON</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> is a great player and he has numbers of achievements such as </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #7068B3\"><span class=\"spark-nlp-display-entity-name\">a World Cup </span><span class=\"spark-nlp-display-entity-type\">EVENT</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, a </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #7068B3\"><span class=\"spark-nlp-display-entity-name\">UEFA Champions League </span><span class=\"spark-nlp-display-entity-type\">EVENT</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> title in his career.<br>             However, he declared his retirement </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #a6b1e1\"><span class=\"spark-nlp-display-entity-name\">last week </span><span class=\"spark-nlp-display-entity-type\">DATE</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> on </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #BE476E\"><span class=\"spark-nlp-display-entity-name\">BBCSport </span><span class=\"spark-nlp-display-entity-type\">ORG</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> livestream</span></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oivyCpmvsQRd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}